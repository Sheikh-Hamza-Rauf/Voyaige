{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "917d0a5c-8055-4bbc-9d59-49b9d4a4cacc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.0.240\n",
      "  Using cached langchain-0.0.240-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from langchain==0.0.240) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from langchain==0.0.240) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from langchain==0.0.240) (3.9.5)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.240)\n",
      "  Using cached dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.11 (from langchain==0.0.240)\n",
      "  Using cached langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from langchain==0.0.240) (2.8.7)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from langchain==0.0.240) (1.26.4)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.240)\n",
      "  Using cached openapi_schema_pydantic-1.2.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting pydantic<2,>=1 (from langchain==0.0.240)\n",
      "  Using cached pydantic-1.10.18-cp312-cp312-win_amd64.whl.metadata (153 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from langchain==0.0.240) (2.32.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from langchain==0.0.240) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.240) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.240) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.240) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.240) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.240) (1.9.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.240)\n",
      "  Using cached marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.240)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from pydantic<2,>=1->langchain==0.0.240) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.240) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.240) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.240) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.0.240) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.240) (3.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.240) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.240) (1.0.0)\n",
      "Using cached langchain-0.0.240-py3-none-any.whl (1.4 MB)\n",
      "Using cached dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Using cached langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
      "Using cached openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "Using cached pydantic-1.10.18-cp312-cp312-win_amd64.whl (1.9 MB)\n",
      "Using cached marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, pydantic, marshmallow, openapi-schema-pydantic, langsmith, dataclasses-json, langchain\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "Successfully installed dataclasses-json-0.5.14 langchain-0.0.240 langsmith-0.0.92 marshmallow-3.22.0 openapi-schema-pydantic-1.2.4 pydantic-1.10.18 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.0.240 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12cd996b-20e7-4742-8fbb-ad867fbc0078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\aamir\\AppData\\Local\\Temp\\ipykernel_12860\\4080736814.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\aamir\\AppData\\Local\\Temp\\ipykernel_12860\\4080736814.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[0;32m     62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0442343-3408-4895-8631-dffe50ec95d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.0.2\n",
      "  Using cached scikit-learn-1.0.2.tar.gz (6.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [33 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 112, in get_requires_for_build_wheel\n",
      "      backend = _build_backend()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\aamir\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n",
      "      obj = import_module(mod_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\aamir\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "      return _bootstrap._gcd_import(name[level:], package, level)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "    File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "    File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "    File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "    File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "    File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "    File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "    File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "    File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "    File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "    File \"C:\\Users\\aamir\\AppData\\Local\\Temp\\pip-build-env-dymralci\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 16, in <module>\n",
      "      import setuptools.version\n",
      "    File \"C:\\Users\\aamir\\AppData\\Local\\Temp\\pip-build-env-dymralci\\overlay\\Lib\\site-packages\\setuptools\\version.py\", line 1, in <module>\n",
      "      import pkg_resources\n",
      "    File \"C:\\Users\\aamir\\AppData\\Local\\Temp\\pip-build-env-dymralci\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 2172, in <module>\n",
      "      register_finder(pkgutil.ImpImporter, find_on_path)\n",
      "                      ^^^^^^^^^^^^^^^^^^^\n",
      "  AttributeError: module 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf201b0-a95f-45f0-a360-bfee36c25bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ac8db0-006a-43ca-9e02-a3fc768eedba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.20.1\n",
      "  Using cached transformers-4.20.1-py3-none-any.whl.metadata (77 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers==4.20.1) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0 (from transformers==4.20.1)\n",
      "  Using cached huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers==4.20.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers==4.20.1) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers==4.20.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers==4.20.1) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers==4.20.1) (2.32.2)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.20.1)\n",
      "  Using cached tokenizers-0.12.1.tar.gz (220 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers==4.20.1) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.20.1) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests->transformers==4.20.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests->transformers==4.20.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests->transformers==4.20.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests->transformers==4.20.1) (2024.6.2)\n",
      "Using cached transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "Using cached huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml): started\n",
      "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
      "Failed to build tokenizers\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for tokenizers (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [49 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\n",
      "  copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\models\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\decoders\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\normalizers\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\pre_tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\processors\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\trainers\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\visualizer.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\n",
      "  copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\tools\\visualizer-styles.css -> build\\lib.win-amd64-cpython-312\\tokenizers\\tools\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a3741b7-9b98-420c-a769-cb364d96e0d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers==0.10.3\n",
      "  Downloading tokenizers-0.10.3.tar.gz (212 kB)\n",
      "     ---------------------------------------- 0.0/212.7 kB ? eta -:--:--\n",
      "     ----- --------------------------------- 30.7/212.7 kB 1.3 MB/s eta 0:00:01\n",
      "     ----- --------------------------------- 30.7/212.7 kB 1.3 MB/s eta 0:00:01\n",
      "     ------- ----------------------------- 41.0/212.7 kB 217.9 kB/s eta 0:00:01\n",
      "     -------- ---------------------------- 51.2/212.7 kB 262.6 kB/s eta 0:00:01\n",
      "     ------------ ------------------------ 71.7/212.7 kB 280.5 kB/s eta 0:00:01\n",
      "     ---------------- -------------------- 92.2/212.7 kB 308.0 kB/s eta 0:00:01\n",
      "     ----------------- ------------------ 102.4/212.7 kB 294.4 kB/s eta 0:00:01\n",
      "     -------------------- --------------- 122.9/212.7 kB 313.8 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 174.1/212.7 kB 374.1 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 184.3/212.7 kB 384.3 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 204.8/212.7 kB 389.1 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 204.8/212.7 kB 389.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ 212.7/212.7 kB 324.0 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml): started\n",
      "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
      "Failed to build tokenizers\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for tokenizers (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [49 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\n",
      "  copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\models\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\decoders\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\normalizers\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\pre_tokenizers\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\processors\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\trainers\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "  creating build\\lib.win-amd64-cpython-312\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\visualizer.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\tools\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\tools\n",
      "  copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\n",
      "  copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\models\n",
      "  copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\decoders\n",
      "  copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\normalizers\n",
      "  copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\pre_tokenizers\n",
      "  copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\processors\n",
      "  copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\trainers\n",
      "  copying py_src\\tokenizers\\tools\\visualizer-styles.css -> build\\lib.win-amd64-cpython-312\\tokenizers\\tools\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install tokenizers==0.10.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f032c5-014b-40ca-ae29-6b67176dc642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad964dd3-7244-44ef-bc00-11973e932a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.3.0\n",
      "  Downloading torch-2.3.0-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from torch==2.3.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from torch==2.3.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from torch==2.3.0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from torch==2.3.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from torch==2.3.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from torch==2.3.0) (2024.3.1)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch==2.3.0)\n",
      "  Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0)\n",
      "  Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0)\n",
      "  Downloading tbb-2021.13.1-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jinja2->torch==2.3.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from sympy->torch==2.3.0) (1.3.0)\n",
      "Downloading torch-2.3.0-cp312-cp312-win_amd64.whl (159.7 MB)\n",
      "   ---------------------------------------- 0.0/159.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/159.7 MB 1.3 MB/s eta 0:02:05\n",
      "   ---------------------------------------- 0.0/159.7 MB 991.0 kB/s eta 0:02:42\n",
      "   ---------------------------------------- 0.1/159.7 MB 469.7 kB/s eta 0:05:40\n",
      "   ---------------------------------------- 0.1/159.7 MB 656.4 kB/s eta 0:04:04\n",
      "   ---------------------------------------- 0.1/159.7 MB 656.4 kB/s eta 0:04:04\n",
      "   ---------------------------------------- 0.2/159.7 MB 655.4 kB/s eta 0:04:04\n",
      "   ---------------------------------------- 0.2/159.7 MB 838.1 kB/s eta 0:03:11\n",
      "   ---------------------------------------- 0.2/159.7 MB 838.1 kB/s eta 0:03:11\n",
      "   ---------------------------------------- 0.4/159.7 MB 1.0 MB/s eta 0:02:37\n",
      "   ---------------------------------------- 0.5/159.7 MB 1.2 MB/s eta 0:02:15\n",
      "   ---------------------------------------- 0.6/159.7 MB 1.3 MB/s eta 0:02:06\n",
      "   ---------------------------------------- 1.0/159.7 MB 1.8 MB/s eta 0:01:29\n",
      "   ---------------------------------------- 1.0/159.7 MB 1.9 MB/s eta 0:01:24\n",
      "   ---------------------------------------- 1.0/159.7 MB 1.7 MB/s eta 0:01:32\n",
      "   ---------------------------------------- 1.0/159.7 MB 1.7 MB/s eta 0:01:32\n",
      "   ---------------------------------------- 1.0/159.7 MB 1.7 MB/s eta 0:01:32\n",
      "   ---------------------------------------- 1.0/159.7 MB 1.7 MB/s eta 0:01:32\n",
      "   ---------------------------------------- 1.6/159.7 MB 2.0 MB/s eta 0:01:18\n",
      "    --------------------------------------- 2.1/159.7 MB 2.5 MB/s eta 0:01:05\n",
      "    --------------------------------------- 2.3/159.7 MB 2.5 MB/s eta 0:01:04\n",
      "    --------------------------------------- 2.3/159.7 MB 2.5 MB/s eta 0:01:04\n",
      "    --------------------------------------- 3.1/159.7 MB 3.1 MB/s eta 0:00:51\n",
      "    --------------------------------------- 3.9/159.7 MB 3.7 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 4.3/159.7 MB 4.0 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 4.9/159.7 MB 4.3 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 5.3/159.7 MB 4.4 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 6.0/159.7 MB 4.9 MB/s eta 0:00:32\n",
      "   - -------------------------------------- 6.3/159.7 MB 5.0 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 6.9/159.7 MB 5.2 MB/s eta 0:00:30\n",
      "   - -------------------------------------- 7.3/159.7 MB 5.4 MB/s eta 0:00:28\n",
      "   - -------------------------------------- 7.9/159.7 MB 5.6 MB/s eta 0:00:28\n",
      "   -- ------------------------------------- 8.4/159.7 MB 5.8 MB/s eta 0:00:27\n",
      "   -- ------------------------------------- 8.8/159.7 MB 5.9 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 9.4/159.7 MB 6.2 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 9.4/159.7 MB 6.2 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 9.4/159.7 MB 6.2 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 9.4/159.7 MB 6.2 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 9.4/159.7 MB 6.2 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 9.4/159.7 MB 6.2 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 9.4/159.7 MB 6.2 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 9.7/159.7 MB 5.2 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 10.5/159.7 MB 6.5 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 10.8/159.7 MB 6.9 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 11.5/159.7 MB 8.3 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 12.2/159.7 MB 8.3 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 12.8/159.7 MB 9.0 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 13.5/159.7 MB 8.8 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 14.1/159.7 MB 8.8 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 14.7/159.7 MB 9.1 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 15.5/159.7 MB 9.1 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 15.7/159.7 MB 9.2 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 15.7/159.7 MB 9.2 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 15.7/159.7 MB 9.2 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 15.7/159.7 MB 9.2 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 15.7/159.7 MB 9.2 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 15.7/159.7 MB 9.2 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 15.7/159.7 MB 9.2 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 15.9/159.7 MB 7.0 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 16.6/159.7 MB 7.2 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 16.8/159.7 MB 7.2 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 17.3/159.7 MB 6.9 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 18.0/159.7 MB 7.0 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 18.7/159.7 MB 7.2 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 18.9/159.7 MB 7.3 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 18.9/159.7 MB 7.3 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 18.9/159.7 MB 7.3 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 18.9/159.7 MB 7.3 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 18.9/159.7 MB 7.3 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 18.9/159.7 MB 7.3 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 18.9/159.7 MB 7.3 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 18.9/159.7 MB 7.3 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 18.9/159.7 MB 5.6 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 19.8/159.7 MB 6.8 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 19.9/159.7 MB 6.8 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 20.2/159.7 MB 6.5 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 21.0/159.7 MB 6.7 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 21.4/159.7 MB 6.6 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 22.0/159.7 MB 6.5 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 22.6/159.7 MB 6.5 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 23.1/159.7 MB 6.5 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 23.4/159.7 MB 6.4 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 23.5/159.7 MB 6.3 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 24.5/159.7 MB 6.3 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 25.1/159.7 MB 6.4 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 25.8/159.7 MB 6.3 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 26.6/159.7 MB 8.1 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 27.4/159.7 MB 8.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 28.1/159.7 MB 8.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 28.3/159.7 MB 8.4 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 28.5/159.7 MB 8.0 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 29.4/159.7 MB 11.9 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 29.4/159.7 MB 11.9 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 29.4/159.7 MB 11.9 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 29.4/159.7 MB 11.9 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 29.4/159.7 MB 11.9 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 29.6/159.7 MB 9.4 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 30.5/159.7 MB 10.1 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 31.3/159.7 MB 10.2 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 31.5/159.7 MB 10.4 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 31.8/159.7 MB 9.6 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 32.5/159.7 MB 10.1 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 32.5/159.7 MB 10.1 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 32.5/159.7 MB 10.1 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 32.5/159.7 MB 10.1 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 32.5/159.7 MB 10.1 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 32.5/159.7 MB 10.1 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 32.5/159.7 MB 10.1 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 33.1/159.7 MB 7.7 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 33.5/159.7 MB 7.9 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 33.7/159.7 MB 7.8 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 33.7/159.7 MB 7.8 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 33.8/159.7 MB 7.5 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 33.9/159.7 MB 7.2 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 34.1/159.7 MB 7.0 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 34.4/159.7 MB 6.7 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 34.6/159.7 MB 6.8 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 34.6/159.7 MB 6.8 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 35.2/159.7 MB 6.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 35.6/159.7 MB 6.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 35.6/159.7 MB 6.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 35.6/159.7 MB 6.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 35.6/159.7 MB 6.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 35.6/159.7 MB 6.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 35.6/159.7 MB 6.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 35.6/159.7 MB 6.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 35.6/159.7 MB 6.5 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 36.3/159.7 MB 5.3 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 36.7/159.7 MB 5.3 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 36.8/159.7 MB 5.2 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 37.7/159.7 MB 5.2 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 37.9/159.7 MB 5.1 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 38.6/159.7 MB 5.2 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 38.9/159.7 MB 5.2 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 39.7/159.7 MB 5.7 MB/s eta 0:00:21\n",
      "   --------- ------------------------------ 39.9/159.7 MB 5.6 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 40.7/159.7 MB 5.6 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 40.9/159.7 MB 5.5 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 41.7/159.7 MB 5.5 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 41.9/159.7 MB 5.7 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 42.5/159.7 MB 5.6 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 43.0/159.7 MB 6.7 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 43.5/159.7 MB 6.5 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 44.2/159.7 MB 7.4 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 44.9/159.7 MB 8.3 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 45.1/159.7 MB 8.3 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 45.5/159.7 MB 7.9 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 46.1/159.7 MB 10.9 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 46.1/159.7 MB 10.9 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 46.8/159.7 MB 10.4 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 47.2/159.7 MB 10.9 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 47.2/159.7 MB 10.9 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 47.5/159.7 MB 9.9 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 48.2/159.7 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 48.4/159.7 MB 9.8 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 49.1/159.7 MB 10.1 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 49.8/159.7 MB 10.1 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 50.6/159.7 MB 10.4 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 51.4/159.7 MB 10.7 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 52.0/159.7 MB 10.7 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 52.8/159.7 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 53.6/159.7 MB 11.5 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 54.4/159.7 MB 11.7 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 54.5/159.7 MB 11.5 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 54.5/159.7 MB 11.5 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 54.7/159.7 MB 10.2 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 55.4/159.7 MB 10.7 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 55.7/159.7 MB 10.6 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 56.3/159.7 MB 10.4 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 56.6/159.7 MB 11.1 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 57.0/159.7 MB 10.6 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 57.7/159.7 MB 11.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 58.2/159.7 MB 11.5 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 58.7/159.7 MB 11.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 59.3/159.7 MB 11.5 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 59.8/159.7 MB 11.7 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 60.4/159.7 MB 11.3 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 60.8/159.7 MB 11.5 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 61.2/159.7 MB 10.7 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 61.9/159.7 MB 10.9 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 62.2/159.7 MB 10.6 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 62.9/159.7 MB 10.6 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 63.2/159.7 MB 10.1 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 64.0/159.7 MB 10.2 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 64.0/159.7 MB 9.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 64.7/159.7 MB 9.8 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 65.2/159.7 MB 10.7 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 66.0/159.7 MB 11.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 66.1/159.7 MB 11.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 66.1/159.7 MB 11.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 66.1/159.7 MB 11.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 66.1/159.7 MB 11.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 66.1/159.7 MB 11.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 66.1/159.7 MB 11.1 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 66.2/159.7 MB 8.3 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 66.9/159.7 MB 8.6 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 67.1/159.7 MB 8.6 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 67.6/159.7 MB 8.3 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 68.2/159.7 MB 8.5 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 68.8/159.7 MB 8.3 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 69.2/159.7 MB 8.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 70.0/159.7 MB 8.3 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 70.2/159.7 MB 8.5 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 70.8/159.7 MB 8.3 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 71.3/159.7 MB 8.5 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 71.3/159.7 MB 8.5 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 71.4/159.7 MB 7.9 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 72.0/159.7 MB 7.8 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 72.3/159.7 MB 7.9 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 73.0/159.7 MB 7.8 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 73.4/159.7 MB 7.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 73.8/159.7 MB 7.7 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 74.4/159.7 MB 7.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 75.2/159.7 MB 7.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 75.7/159.7 MB 8.0 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 76.4/159.7 MB 10.4 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 76.5/159.7 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 77.2/159.7 MB 10.1 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 77.6/159.7 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 78.2/159.7 MB 10.2 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 78.6/159.7 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 78.9/159.7 MB 9.9 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 79.6/159.7 MB 10.1 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 79.8/159.7 MB 9.9 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 80.5/159.7 MB 10.1 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 81.1/159.7 MB 10.2 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 81.9/159.7 MB 11.3 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 82.6/159.7 MB 11.9 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 83.3/159.7 MB 11.7 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 83.9/159.7 MB 12.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 83.9/159.7 MB 12.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 83.9/159.7 MB 12.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 83.9/159.7 MB 12.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 83.9/159.7 MB 12.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 83.9/159.7 MB 12.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 84.7/159.7 MB 9.6 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 85.0/159.7 MB 9.4 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 85.0/159.7 MB 9.4 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 85.7/159.7 MB 9.0 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 86.2/159.7 MB 9.0 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 86.7/159.7 MB 8.8 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 87.1/159.7 MB 9.0 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 87.8/159.7 MB 9.0 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 88.1/159.7 MB 9.2 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 88.4/159.7 MB 8.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 89.1/159.7 MB 9.1 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 89.8/159.7 MB 9.1 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 90.2/159.7 MB 9.2 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 90.9/159.7 MB 9.2 MB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 91.5/159.7 MB 9.2 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 92.3/159.7 MB 9.2 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 92.8/159.7 MB 9.1 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 93.4/159.7 MB 9.1 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 94.1/159.7 MB 9.1 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 94.5/159.7 MB 11.3 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 95.4/159.7 MB 12.4 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 95.4/159.7 MB 12.4 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 96.2/159.7 MB 11.9 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 96.8/159.7 MB 11.9 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 97.5/159.7 MB 12.6 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 98.3/159.7 MB 13.4 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 98.6/159.7 MB 13.4 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 99.2/159.7 MB 12.6 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 99.6/159.7 MB 12.9 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 100.1/159.7 MB 12.6 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 100.7/159.7 MB 12.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 100.9/159.7 MB 12.4 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 101.7/159.7 MB 12.4 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 102.1/159.7 MB 11.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 102.8/159.7 MB 11.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 102.8/159.7 MB 11.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 103.3/159.7 MB 11.3 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 103.8/159.7 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 104.3/159.7 MB 11.1 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 104.9/159.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.2/159.7 MB 10.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.9/159.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.9/159.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.9/159.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.9/159.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.9/159.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.9/159.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.9/159.7 MB 11.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 105.9/159.7 MB 11.3 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 106.6/159.7 MB 8.2 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 107.4/159.7 MB 8.3 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 108.0/159.7 MB 8.4 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 108.0/159.7 MB 8.4 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 108.6/159.7 MB 7.9 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 109.0/159.7 MB 8.2 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 109.6/159.7 MB 8.0 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 110.2/159.7 MB 8.1 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 110.8/159.7 MB 8.0 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 111.5/159.7 MB 8.3 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 112.4/159.7 MB 8.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 113.2/159.7 MB 9.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 113.2/159.7 MB 9.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 113.2/159.7 MB 9.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 113.2/159.7 MB 9.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 113.2/159.7 MB 9.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 113.2/159.7 MB 9.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 113.2/159.7 MB 9.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 113.2/159.7 MB 9.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 113.7/159.7 MB 6.9 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 114.3/159.7 MB 7.0 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 114.8/159.7 MB 6.9 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 115.3/159.7 MB 7.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 115.8/159.7 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 116.4/159.7 MB 9.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 116.4/159.7 MB 9.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 116.4/159.7 MB 9.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 116.4/159.7 MB 9.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 116.4/159.7 MB 9.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 116.4/159.7 MB 9.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 116.4/159.7 MB 9.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 117.1/159.7 MB 7.1 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 117.4/159.7 MB 7.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 117.4/159.7 MB 7.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 118.2/159.7 MB 7.2 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 119.1/159.7 MB 7.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 119.8/159.7 MB 7.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 120.6/159.7 MB 7.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 121.4/159.7 MB 7.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 122.1/159.7 MB 7.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 122.7/159.7 MB 7.4 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 123.5/159.7 MB 7.4 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 123.7/159.7 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 124.5/159.7 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 124.8/159.7 MB 9.8 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 125.5/159.7 MB 9.5 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 125.8/159.7 MB 9.6 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 126.4/159.7 MB 9.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 127.2/159.7 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 128.0/159.7 MB 14.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 128.6/159.7 MB 13.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 129.3/159.7 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 130.0/159.7 MB 13.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 130.1/159.7 MB 13.1 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 130.8/159.7 MB 12.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.1/159.7 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.1/159.7 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.1/159.7 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.1/159.7 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.1/159.7 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.1/159.7 MB 12.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.1/159.7 MB 12.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 131.7/159.7 MB 9.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 132.1/159.7 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 132.1/159.7 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 132.1/159.7 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 132.1/159.7 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 132.1/159.7 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 132.1/159.7 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 132.1/159.7 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 132.1/159.7 MB 9.4 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 132.8/159.7 MB 7.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 133.2/159.7 MB 7.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 133.9/159.7 MB 7.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 134.2/159.7 MB 7.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 134.6/159.7 MB 6.9 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 135.3/159.7 MB 7.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 135.5/159.7 MB 6.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 136.3/159.7 MB 7.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 136.3/159.7 MB 7.0 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 137.2/159.7 MB 6.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 137.6/159.7 MB 6.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 138.4/159.7 MB 6.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 138.4/159.7 MB 6.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 139.0/159.7 MB 6.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 139.5/159.7 MB 6.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 140.1/159.7 MB 6.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 140.5/159.7 MB 6.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 140.5/159.7 MB 6.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 141.1/159.7 MB 6.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 141.9/159.7 MB 7.8 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 142.6/159.7 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 142.6/159.7 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 142.6/159.7 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 142.6/159.7 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 142.6/159.7 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 142.6/159.7 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 142.6/159.7 MB 10.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 143.1/159.7 MB 8.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 143.6/159.7 MB 8.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 144.4/159.7 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 144.7/159.7 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 145.0/159.7 MB 8.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 145.7/159.7 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 145.9/159.7 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 146.8/159.7 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 146.8/159.7 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 147.5/159.7 MB 8.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 147.8/159.7 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 148.6/159.7 MB 8.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 149.0/159.7 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 149.0/159.7 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 149.0/159.7 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 149.0/159.7 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 149.0/159.7 MB 8.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 153.6/159.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 154.1/159.7 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 154.6/159.7 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.2/159.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.2/159.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.2/159.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.2/159.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.2/159.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.2/159.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.2/159.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.2/159.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.2/159.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  155.9/159.7 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  156.2/159.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  156.9/159.7 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  157.6/159.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  158.3/159.7 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  159.0/159.7 MB 9.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.7/159.7 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 159.7/159.7 MB 8.1 MB/s eta 0:00:00\n",
      "Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "   ---------------------------------------- 0.0/228.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/228.5 MB 20.5 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 1.9/228.5 MB 20.3 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 2.8/228.5 MB 19.5 MB/s eta 0:00:12\n",
      "    --------------------------------------- 3.7/228.5 MB 19.4 MB/s eta 0:00:12\n",
      "    --------------------------------------- 4.4/228.5 MB 18.9 MB/s eta 0:00:12\n",
      "    --------------------------------------- 5.0/228.5 MB 17.8 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 5.9/228.5 MB 18.0 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 6.8/228.5 MB 18.1 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 7.4/228.5 MB 17.6 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 8.3/228.5 MB 17.7 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 9.2/228.5 MB 17.7 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 10.1/228.5 MB 17.8 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 10.6/228.5 MB 17.2 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 11.5/228.5 MB 17.3 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 12.5/228.5 MB 17.3 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 13.2/228.5 MB 17.2 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 14.1/228.5 MB 17.2 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 14.9/228.5 MB 17.2 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 15.6/228.5 MB 17.7 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 16.5/228.5 MB 17.2 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 17.3/228.5 MB 17.2 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 18.3/228.5 MB 17.7 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 19.0/228.5 MB 18.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 19.7/228.5 MB 17.7 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 20.6/228.5 MB 17.7 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 21.5/228.5 MB 18.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 22.3/228.5 MB 18.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 22.8/228.5 MB 17.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 23.6/228.5 MB 17.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 24.4/228.5 MB 17.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 25.1/228.5 MB 17.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 25.9/228.5 MB 17.2 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 26.5/228.5 MB 16.8 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 27.2/228.5 MB 16.4 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 27.9/228.5 MB 16.4 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 29.0/228.5 MB 16.4 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 29.9/228.5 MB 16.8 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 30.8/228.5 MB 16.8 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 31.6/228.5 MB 16.8 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 32.4/228.5 MB 16.8 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 33.1/228.5 MB 17.3 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 33.8/228.5 MB 16.8 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 34.6/228.5 MB 16.8 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 35.4/228.5 MB 16.8 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 36.3/228.5 MB 17.2 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 37.1/228.5 MB 17.7 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 38.1/228.5 MB 18.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 39.1/228.5 MB 18.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 39.9/228.5 MB 18.2 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 40.8/228.5 MB 17.7 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 41.7/228.5 MB 18.2 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 42.5/228.5 MB 18.2 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 43.4/228.5 MB 18.2 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 44.1/228.5 MB 18.2 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 45.0/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 45.8/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 46.7/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 47.6/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 48.4/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 49.3/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 50.1/228.5 MB 18.2 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 51.0/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 51.9/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 52.7/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 53.5/228.5 MB 18.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 54.3/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 55.2/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 56.0/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 56.9/228.5 MB 18.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 57.8/228.5 MB 18.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 58.7/228.5 MB 18.7 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 59.5/228.5 MB 18.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 60.5/228.5 MB 18.7 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 61.2/228.5 MB 18.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 62.1/228.5 MB 18.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 62.6/228.5 MB 18.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 63.4/228.5 MB 17.7 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 64.2/228.5 MB 17.7 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 65.0/228.5 MB 17.7 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 65.9/228.5 MB 17.7 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 66.9/228.5 MB 17.7 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 67.7/228.5 MB 17.7 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 68.5/228.5 MB 17.7 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 69.3/228.5 MB 17.3 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 70.1/228.5 MB 17.3 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 70.9/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 71.8/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 72.4/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 73.3/228.5 MB 18.2 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 74.1/228.5 MB 18.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 75.0/228.5 MB 18.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 75.7/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 76.5/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 77.3/228.5 MB 17.2 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 78.2/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 79.0/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 79.8/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 80.7/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 81.5/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 82.3/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 83.1/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 84.0/228.5 MB 17.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 85.0/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 85.8/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 86.5/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 87.4/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 88.3/228.5 MB 18.7 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 89.2/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 90.0/228.5 MB 18.7 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 90.9/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 91.8/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 92.5/228.5 MB 18.7 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 93.4/228.5 MB 18.7 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 94.2/228.5 MB 18.7 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 95.1/228.5 MB 18.7 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 95.8/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 96.8/228.5 MB 18.7 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 97.5/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 98.4/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 99.1/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 100.1/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 101.0/228.5 MB 18.2 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 101.9/228.5 MB 18.2 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 102.7/228.5 MB 18.2 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 103.5/228.5 MB 18.2 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 104.4/228.5 MB 18.2 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 105.2/228.5 MB 18.2 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 106.0/228.5 MB 18.2 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 106.7/228.5 MB 18.2 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 107.2/228.5 MB 17.3 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 108.0/228.5 MB 17.3 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 108.7/228.5 MB 17.2 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 109.5/228.5 MB 17.2 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 110.4/228.5 MB 17.2 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 111.2/228.5 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 111.9/228.5 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 112.7/228.5 MB 16.4 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 113.5/228.5 MB 17.2 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 114.4/228.5 MB 16.4 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 115.2/228.5 MB 16.4 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 116.0/228.5 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 116.9/228.5 MB 16.8 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 117.7/228.5 MB 17.2 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 118.6/228.5 MB 17.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 119.4/228.5 MB 17.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 120.4/228.5 MB 17.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 121.1/228.5 MB 17.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 121.9/228.5 MB 18.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 122.7/228.5 MB 18.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 123.5/228.5 MB 18.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 124.3/228.5 MB 18.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 125.0/228.5 MB 17.7 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 125.8/228.5 MB 18.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 126.6/228.5 MB 17.7 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 127.3/228.5 MB 17.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 128.2/228.5 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 129.1/228.5 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 129.9/228.5 MB 17.3 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 130.9/228.5 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 131.5/228.5 MB 17.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 132.4/228.5 MB 17.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 133.2/228.5 MB 17.7 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 134.0/228.5 MB 17.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 134.9/228.5 MB 17.7 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 135.7/228.5 MB 17.7 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 136.1/228.5 MB 18.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 136.9/228.5 MB 17.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 137.8/228.5 MB 17.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 138.6/228.5 MB 17.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 139.5/228.5 MB 17.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 140.1/228.5 MB 16.8 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 140.8/228.5 MB 16.4 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 141.7/228.5 MB 16.8 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 142.5/228.5 MB 16.8 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 143.5/228.5 MB 16.8 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 144.3/228.5 MB 16.8 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 144.7/228.5 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 145.5/228.5 MB 16.4 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 146.5/228.5 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 147.4/228.5 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 148.3/228.5 MB 17.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 148.9/228.5 MB 17.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 149.5/228.5 MB 16.4 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 150.2/228.5 MB 16.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 151.1/228.5 MB 17.3 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 152.0/228.5 MB 16.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 152.7/228.5 MB 17.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 153.4/228.5 MB 17.3 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 153.9/228.5 MB 16.4 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 154.9/228.5 MB 16.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 155.7/228.5 MB 16.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 156.5/228.5 MB 16.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 157.4/228.5 MB 16.8 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 158.2/228.5 MB 16.8 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 159.2/228.5 MB 17.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 160.1/228.5 MB 17.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 160.8/228.5 MB 17.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 161.6/228.5 MB 17.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 162.4/228.5 MB 17.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 162.9/228.5 MB 16.8 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 163.7/228.5 MB 17.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 164.5/228.5 MB 17.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 165.3/228.5 MB 17.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 166.1/228.5 MB 17.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 167.0/228.5 MB 17.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 167.6/228.5 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 168.3/228.5 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 169.1/228.5 MB 16.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 170.0/228.5 MB 16.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 170.9/228.5 MB 16.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 171.6/228.5 MB 16.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 172.4/228.5 MB 16.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 173.1/228.5 MB 16.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 173.6/228.5 MB 16.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 174.6/228.5 MB 16.8 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 175.5/228.5 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 176.3/228.5 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 177.0/228.5 MB 16.4 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 177.8/228.5 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 178.6/228.5 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 179.6/228.5 MB 17.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 180.3/228.5 MB 17.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 181.2/228.5 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 181.8/228.5 MB 17.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 182.5/228.5 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 183.3/228.5 MB 17.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 184.0/228.5 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 184.8/228.5 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 185.4/228.5 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 186.3/228.5 MB 16.8 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 187.1/228.5 MB 16.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 188.1/228.5 MB 17.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 188.9/228.5 MB 17.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 189.9/228.5 MB 17.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 190.9/228.5 MB 17.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 191.6/228.5 MB 17.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 192.5/228.5 MB 18.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 192.9/228.5 MB 17.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 192.9/228.5 MB 17.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 192.9/228.5 MB 17.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 192.9/228.5 MB 17.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 192.9/228.5 MB 17.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 192.9/228.5 MB 17.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 192.9/228.5 MB 17.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 193.3/228.5 MB 11.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 194.2/228.5 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 194.2/228.5 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 194.2/228.5 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 194.2/228.5 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 196.0/228.5 MB 10.7 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 198.3/228.5 MB 11.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 199.2/228.5 MB 11.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 199.7/228.5 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 200.1/228.5 MB 10.9 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 201.1/228.5 MB 11.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 201.6/228.5 MB 11.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 201.9/228.5 MB 10.7 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 202.1/228.5 MB 10.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 202.5/228.5 MB 10.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 203.4/228.5 MB 14.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 204.4/228.5 MB 14.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 205.1/228.5 MB 18.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 206.1/228.5 MB 17.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 206.8/228.5 MB 16.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 207.7/228.5 MB 14.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 208.6/228.5 MB 14.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 209.4/228.5 MB 14.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 210.2/228.5 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 211.0/228.5 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 211.8/228.5 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 212.6/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 213.7/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 214.4/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 215.3/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 216.1/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 217.0/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 217.8/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 218.7/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 219.6/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 220.5/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 221.3/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 222.2/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  223.1/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  223.8/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  224.7/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  225.5/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  226.3/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  227.3/228.5 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.2/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 228.5/228.5 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.7/3.5 MB 14.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.5/3.5 MB 15.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.4/3.5 MB 16.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.2/3.5 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 16.0 MB/s eta 0:00:00\n",
      "Downloading tbb-2021.13.1-py3-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 286.9/286.9 kB 17.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tbb, intel-openmp, mkl, torch\n",
      "Successfully installed intel-openmp-2021.4.0 mkl-2021.4.0 tbb-2021.13.1 torch-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e14c0-014d-4037-bfd0-e16f09b55d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with sample data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77cdd0ee-2d2b-4559-bc3c-fdaeeef9bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    hotel_name      city  hotel_cost     restaurant_name  restaurant_cost  \\\n",
      "0  Hotel Paris     Paris         100            Bistro A               25   \n",
      "1   Grand Bali      Bali          80         Warung Bali               15   \n",
      "2    NYC Hotel  New York         120            Deli NYC               30   \n",
      "3    Tokyo Inn     Tokyo         100          Sushi Taro               40   \n",
      "4   Rome Hotel      Rome          90  Trattoria da Luigi               35   \n",
      "\n",
      "      attraction_name  attraction_cost  transportation_cost  Pool  WiFi  Gym  \\\n",
      "0        Eiffel Tower               10                   15     0     1    0   \n",
      "1  Ubud Monkey Forest                8                   10     1     0    0   \n",
      "2   Statue of Liberty               15                   20     0     1    0   \n",
      "3         Tokyo Tower               20                   12     0     1    0   \n",
      "4           Colosseum               12                   10     0     1    0   \n",
      "\n",
      "   Breakfast  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the first column is not used as an index\n",
    "df = pd.read_csv('data.csv', header=0)  # Ensure the first row is used as headers\n",
    "\n",
    "# Split the facilities column into individual components\n",
    "df['facilities'] = df['facilities'].str.split(';')\n",
    "\n",
    "# Get a list of all unique facilities in the dataset\n",
    "all_facilities = set()\n",
    "df['facilities'].apply(lambda x: all_facilities.update(x))\n",
    "\n",
    "# Create a new column for each unique facility and assign binary values\n",
    "for facility in all_facilities:\n",
    "    df[facility.strip()] = df['facilities'].apply(lambda x: 1 if facility.strip() in x else 0)\n",
    "\n",
    "# Drop the original facilities column\n",
    "df = df.drop('facilities', axis=1)\n",
    "\n",
    "# View the transformed dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Save the updated dataframe to a new CSV\n",
    "df.to_csv('data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa817c-4477-420d-944b-eb1018c4e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading hotel data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c5e31a-7646-428a-8c51-d5f8d2b35289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06cd5658-5906-4e6a-ac4e-b7729ccba1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       _id                 name  \\\n",
      "0     {'$oid': '66bc7a8c0c64f6180de0d84f'}     Midway Residency   \n",
      "1     {'$oid': '66bc7ab70c64f6180de0d850'}  Hotel Royal Comfort   \n",
      "2     {'$oid': '66bc7adc0c64f6180de0d855'}   hostel view garden   \n",
      "3     {'$oid': '66bc7b240c64f6180de0d860'}      WEDNESDAY HOMES   \n",
      "4     {'$oid': '66bc7b670c64f6180de0d86b'}          Prime Motel   \n",
      "...                                    ...                  ...   \n",
      "3467  {'$oid': '66c26096720b39c64cc1bf8c'}  Batakundi Eco Hotel   \n",
      "3468  {'$oid': '66c260e9720b39c64cc1bfa1'}   PTDC Motels, Naran   \n",
      "3469  {'$oid': '66c2612f720b39c64cc1bfab'}    New Lalazar Hotel   \n",
      "3470  {'$oid': '66c26173720b39c64cc1bfb6'}   Rozhok Hotel Naran   \n",
      "3471  {'$oid': '66c261b7720b39c64cc1bfcb'}  Fairy Meadows Hotel   \n",
      "\n",
      "                                                address  \\\n",
      "0     3rd Floor App 301, 143-A Sector, Sector C Comm...   \n",
      "1     F788+W9X, opposite Emporium Mall, Trade Centre...   \n",
      "2     7 Shahrah Aiwan-e-Sanat-o-Tijarat, near china ...   \n",
      "3                                 address not available   \n",
      "4                                 address not available   \n",
      "...                                                 ...   \n",
      "3467  Mansehra - Naran - Jalkhad - Chilas Rd, Bataku...   \n",
      "3468  WM63+J5C, PTDC Motel Area, Naran, Mansehra, Kh...   \n",
      "3469                              address not available   \n",
      "3470  WM57+JG, Katha, Naran, Mansehra, Khyber Pakhtu...   \n",
      "3471                              address not available   \n",
      "\n",
      "                                                 images  price       city  \\\n",
      "0     [https://lh6.googleusercontent.com/proxy/Yu51c...  12648     Lahore   \n",
      "1                                                    []   5218     Lahore   \n",
      "2     [https://lh5.googleusercontent.com/p/AF1QipMzu...  12648     Lahore   \n",
      "3     [https://lh5.googleusercontent.com/p/AF1QipP-y...  12648     Lahore   \n",
      "4     [https://lh5.googleusercontent.com/p/AF1QipOpg...  12648     Lahore   \n",
      "...                                                 ...    ...        ...   \n",
      "3467  [https://lh6.googleusercontent.com/proxy/-_rAe...  21724  Batakundi   \n",
      "3468  [https://lh5.googleusercontent.com/p/AF1QipORx...  12648  Batakundi   \n",
      "3469  [https://lh5.googleusercontent.com/p/AF1QipMTz...  12648  Batakundi   \n",
      "3470  [https://lh5.googleusercontent.com/p/AF1QipOWr...   7424  Batakundi   \n",
      "3471  [https://lh5.googleusercontent.com/proxy/p6y-T...  20176  Batakundi   \n",
      "\n",
      "                                             facilities  \\\n",
      "0            [Parking, Conference Room, BBQ Facilities]   \n",
      "1                               [Terrace, Room Service]   \n",
      "2                             [Fitness Center, Library]   \n",
      "3                       [Laundry, Room Service, Garden]   \n",
      "4                               [Parking, Library, Spa]   \n",
      "...                                                 ...   \n",
      "3467                               [Free Wi-Fi, Garden]   \n",
      "3468                          [Fitness Center, Terrace]   \n",
      "3469            [Room Service, Terrace, BBQ Facilities]   \n",
      "3470                                     [Spa, Library]   \n",
      "3471  [Business Center, Swimming Pool, Currency Exch...   \n",
      "\n",
      "                                                  about  hotel_id  \n",
      "0                                 Check-out time: 12:00         1  \n",
      "1           Perfect for business and leisure travelers.         2  \n",
      "2                  InternetWi-FiPoolsNo poolsNo hot tub         3  \n",
      "3           Perfect for business and leisure travelers.         4  \n",
      "4     InternetWi-FifreeServicesFront desk24-hourFull...         5  \n",
      "...                                                 ...       ...  \n",
      "3467          Check-in time: 14:00Check-out time: 12:00      2302  \n",
      "3468                              Check-out time: 11:00      2303  \n",
      "3469                              Check-out time: 12:00      2304  \n",
      "3470                  Located in the heart of the city.      2305  \n",
      "3471          Check-in time: 14:00Check-out time: 12:00      2306  \n",
      "\n",
      "[3472 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "hotel_df=pd.read_json(\"clean_hotel_data.json\")\n",
    "print(hotel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0575c048-dc66-4140-820e-ae6cdced199b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d9ef30-2934-4f78-842e-783c8943070b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e4a4be-92ff-445f-bad2-c602030ca0dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       _id                 name  \\\n",
      "0     {'$oid': '66bc7a8c0c64f6180de0d84f'}     Midway Residency   \n",
      "1     {'$oid': '66bc7ab70c64f6180de0d850'}  Hotel Royal Comfort   \n",
      "2     {'$oid': '66bc7adc0c64f6180de0d855'}   hostel view garden   \n",
      "3     {'$oid': '66bc7b240c64f6180de0d860'}      WEDNESDAY HOMES   \n",
      "4     {'$oid': '66bc7b670c64f6180de0d86b'}          Prime Motel   \n",
      "...                                    ...                  ...   \n",
      "3467  {'$oid': '66c26096720b39c64cc1bf8c'}  Batakundi Eco Hotel   \n",
      "3468  {'$oid': '66c260e9720b39c64cc1bfa1'}   PTDC Motels, Naran   \n",
      "3469  {'$oid': '66c2612f720b39c64cc1bfab'}    New Lalazar Hotel   \n",
      "3470  {'$oid': '66c26173720b39c64cc1bfb6'}   Rozhok Hotel Naran   \n",
      "3471  {'$oid': '66c261b7720b39c64cc1bfcb'}  Fairy Meadows Hotel   \n",
      "\n",
      "                                                address  \\\n",
      "0     3rd Floor App 301, 143-A Sector, Sector C Comm...   \n",
      "1     F788+W9X, opposite Emporium Mall, Trade Centre...   \n",
      "2     7 Shahrah Aiwan-e-Sanat-o-Tijarat, near china ...   \n",
      "3                                 address not available   \n",
      "4                                 address not available   \n",
      "...                                                 ...   \n",
      "3467  Mansehra - Naran - Jalkhad - Chilas Rd, Bataku...   \n",
      "3468  WM63+J5C, PTDC Motel Area, Naran, Mansehra, Kh...   \n",
      "3469                              address not available   \n",
      "3470  WM57+JG, Katha, Naran, Mansehra, Khyber Pakhtu...   \n",
      "3471                              address not available   \n",
      "\n",
      "                                                 images  price       city  \\\n",
      "0     [https://lh6.googleusercontent.com/proxy/Yu51c...  12648     Lahore   \n",
      "1                                                    []   5218     Lahore   \n",
      "2     [https://lh5.googleusercontent.com/p/AF1QipMzu...  12648     Lahore   \n",
      "3     [https://lh5.googleusercontent.com/p/AF1QipP-y...  12648     Lahore   \n",
      "4     [https://lh5.googleusercontent.com/p/AF1QipOpg...  12648     Lahore   \n",
      "...                                                 ...    ...        ...   \n",
      "3467  [https://lh6.googleusercontent.com/proxy/-_rAe...  21724  Batakundi   \n",
      "3468  [https://lh5.googleusercontent.com/p/AF1QipORx...  12648  Batakundi   \n",
      "3469  [https://lh5.googleusercontent.com/p/AF1QipMTz...  12648  Batakundi   \n",
      "3470  [https://lh5.googleusercontent.com/p/AF1QipOWr...   7424  Batakundi   \n",
      "3471  [https://lh5.googleusercontent.com/proxy/p6y-T...  20176  Batakundi   \n",
      "\n",
      "                                             facilities  \\\n",
      "0            [Parking, Conference Room, BBQ Facilities]   \n",
      "1                               [Terrace, Room Service]   \n",
      "2                             [Fitness Center, Library]   \n",
      "3                       [Laundry, Room Service, Garden]   \n",
      "4                               [Parking, Library, Spa]   \n",
      "...                                                 ...   \n",
      "3467                               [Free Wi-Fi, Garden]   \n",
      "3468                          [Fitness Center, Terrace]   \n",
      "3469            [Room Service, Terrace, BBQ Facilities]   \n",
      "3470                                     [Spa, Library]   \n",
      "3471  [Business Center, Swimming Pool, Currency Exch...   \n",
      "\n",
      "                                                  about  hotel_id  \n",
      "0                                 Check-out time: 12:00         1  \n",
      "1           Perfect for business and leisure travelers.         2  \n",
      "2                  InternetWi-FiPoolsNo poolsNo hot tub         3  \n",
      "3           Perfect for business and leisure travelers.         4  \n",
      "4     InternetWi-FifreeServicesFront desk24-hourFull...         5  \n",
      "...                                                 ...       ...  \n",
      "3467          Check-in time: 14:00Check-out time: 12:00      2302  \n",
      "3468                              Check-out time: 11:00      2303  \n",
      "3469                              Check-out time: 12:00      2304  \n",
      "3470                  Located in the heart of the city.      2305  \n",
      "3471          Check-in time: 14:00Check-out time: 12:00      2306  \n",
      "\n",
      "[3472 rows x 9 columns]\n",
      "{'Cable TV', 'Entire apartment', 'Oven stove', 'Car Rental Service', 'Ironing board', 'bathroom', 'Washing machine', 'Cot', 'Entire bungalow', 'Conference Room', 'Fitness Center', 'Outdoor grill', 'Fitness centre', 'Pet-friendly', 'Entire house', 'Pet Friendly', 'Airport shuttle', 'Terrace', 'Room Service', 'BBQ Facilities', '24-Hour Front Desk', 'Child-friendly', 'Kitchen', 'Microwave', 'Free parking', 'Breakfast Buffet', 'Swimming Pool', 'Paid parking', 'Entire villa', 'Air conditioning', 'Balcony', 'Spa', 'Business Center', 'Free breakfast', 'Currency Exchange', 'Outdoor pool', 'Air Conditioning', 'Laundry', 'Golf Course', 'cafe', 'Indoor pool', 'Parking', 'Garden', 'Patio', 'Fireplace', 'Restaurant', 'Smoking Rooms', 'Babysitting Service', 'Heating', 'Paid Wi-Fi', 'Wheelchair accessible', 'Entire chalet', 'Lift', 'Smoke-free', 'Entire cottage', 'Library', 'Hot tub', 'Beach access', 'Family Rooms', 'Free Wi-Fi'}\n",
      "                                       _id                 name  \\\n",
      "0     {'$oid': '66bc7a8c0c64f6180de0d84f'}     Midway Residency   \n",
      "1     {'$oid': '66bc7ab70c64f6180de0d850'}  Hotel Royal Comfort   \n",
      "2     {'$oid': '66bc7adc0c64f6180de0d855'}   hostel view garden   \n",
      "3     {'$oid': '66bc7b240c64f6180de0d860'}      WEDNESDAY HOMES   \n",
      "4     {'$oid': '66bc7b670c64f6180de0d86b'}          Prime Motel   \n",
      "...                                    ...                  ...   \n",
      "3467  {'$oid': '66c26096720b39c64cc1bf8c'}  Batakundi Eco Hotel   \n",
      "3468  {'$oid': '66c260e9720b39c64cc1bfa1'}   PTDC Motels, Naran   \n",
      "3469  {'$oid': '66c2612f720b39c64cc1bfab'}    New Lalazar Hotel   \n",
      "3470  {'$oid': '66c26173720b39c64cc1bfb6'}   Rozhok Hotel Naran   \n",
      "3471  {'$oid': '66c261b7720b39c64cc1bfcb'}  Fairy Meadows Hotel   \n",
      "\n",
      "                                                address  \\\n",
      "0     3rd Floor App 301, 143-A Sector, Sector C Comm...   \n",
      "1     F788+W9X, opposite Emporium Mall, Trade Centre...   \n",
      "2     7 Shahrah Aiwan-e-Sanat-o-Tijarat, near china ...   \n",
      "3                                 address not available   \n",
      "4                                 address not available   \n",
      "...                                                 ...   \n",
      "3467  Mansehra - Naran - Jalkhad - Chilas Rd, Bataku...   \n",
      "3468  WM63+J5C, PTDC Motel Area, Naran, Mansehra, Kh...   \n",
      "3469                              address not available   \n",
      "3470  WM57+JG, Katha, Naran, Mansehra, Khyber Pakhtu...   \n",
      "3471                              address not available   \n",
      "\n",
      "                                                 images  price       city  \\\n",
      "0     [https://lh6.googleusercontent.com/proxy/Yu51c...  12648     Lahore   \n",
      "1                                                    []   5218     Lahore   \n",
      "2     [https://lh5.googleusercontent.com/p/AF1QipMzu...  12648     Lahore   \n",
      "3     [https://lh5.googleusercontent.com/p/AF1QipP-y...  12648     Lahore   \n",
      "4     [https://lh5.googleusercontent.com/p/AF1QipOpg...  12648     Lahore   \n",
      "...                                                 ...    ...        ...   \n",
      "3467  [https://lh6.googleusercontent.com/proxy/-_rAe...  21724  Batakundi   \n",
      "3468  [https://lh5.googleusercontent.com/p/AF1QipORx...  12648  Batakundi   \n",
      "3469  [https://lh5.googleusercontent.com/p/AF1QipMTz...  12648  Batakundi   \n",
      "3470  [https://lh5.googleusercontent.com/p/AF1QipOWr...   7424  Batakundi   \n",
      "3471  [https://lh5.googleusercontent.com/proxy/p6y-T...  20176  Batakundi   \n",
      "\n",
      "                                                  about  hotel_id  Cable TV  \\\n",
      "0                                 Check-out time: 12:00         1         0   \n",
      "1           Perfect for business and leisure travelers.         2         0   \n",
      "2                  InternetWi-FiPoolsNo poolsNo hot tub         3         0   \n",
      "3           Perfect for business and leisure travelers.         4         0   \n",
      "4     InternetWi-FifreeServicesFront desk24-hourFull...         5         0   \n",
      "...                                                 ...       ...       ...   \n",
      "3467          Check-in time: 14:00Check-out time: 12:00      2302         0   \n",
      "3468                              Check-out time: 11:00      2303         0   \n",
      "3469                              Check-out time: 12:00      2304         0   \n",
      "3470                  Located in the heart of the city.      2305         0   \n",
      "3471          Check-in time: 14:00Check-out time: 12:00      2306         0   \n",
      "\n",
      "      Entire apartment  ...  Wheelchair accessible  Entire chalet  Lift  \\\n",
      "0                    0  ...                      0              0     0   \n",
      "1                    0  ...                      0              0     0   \n",
      "2                    0  ...                      0              0     0   \n",
      "3                    0  ...                      0              0     0   \n",
      "4                    0  ...                      0              0     0   \n",
      "...                ...  ...                    ...            ...   ...   \n",
      "3467                 0  ...                      0              0     0   \n",
      "3468                 0  ...                      0              0     0   \n",
      "3469                 0  ...                      0              0     0   \n",
      "3470                 0  ...                      0              0     0   \n",
      "3471                 0  ...                      0              0     0   \n",
      "\n",
      "      Smoke-free  Entire cottage  Library  Hot tub  Beach access  \\\n",
      "0              0               0        0        0             0   \n",
      "1              0               0        0        0             0   \n",
      "2              0               0        1        0             0   \n",
      "3              0               0        0        0             0   \n",
      "4              0               0        1        0             0   \n",
      "...          ...             ...      ...      ...           ...   \n",
      "3467           0               0        0        0             0   \n",
      "3468           0               0        0        0             0   \n",
      "3469           0               0        0        0             0   \n",
      "3470           0               0        1        0             0   \n",
      "3471           0               0        0        0             0   \n",
      "\n",
      "      Family Rooms  Free Wi-Fi  \n",
      "0                0           0  \n",
      "1                0           0  \n",
      "2                0           0  \n",
      "3                0           0  \n",
      "4                0           0  \n",
      "...            ...         ...  \n",
      "3467             0           1  \n",
      "3468             0           0  \n",
      "3469             0           0  \n",
      "3470             0           0  \n",
      "3471             0           0  \n",
      "\n",
      "[3472 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hotel_df=pd.read_json(\"clean_hotel_data.json\")\n",
    "print(hotel_df)\n",
    "\n",
    "unique_facilities = set(facility for sublist in hotel_df['facilities'] for facility in sublist)\n",
    "\n",
    "print(unique_facilities)\n",
    "# Get unique facilities\n",
    "unique_facilities = set(facility for sublist in hotel_df['facilities'] for facility in sublist)\n",
    "\n",
    "# Create columns for each unique facility\n",
    "for facility in unique_facilities:\n",
    "    hotel_df[facility] = hotel_df['facilities'].apply(lambda x: 1 if facility in x else 0)\n",
    "\n",
    "# Optionally, drop the original facilities column if no longer needed\n",
    "hotel_df.drop(columns=['facilities'], inplace=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(hotel_df)\n",
    "# Save the updated dataframe to a new CSV\n",
    "hotel_df.to_csv('new_hotel_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e656a00-a5d8-42ae-a20d-c3933acdde97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965e378-8e15-4903-83cd-061eb0a9472d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b32878-2fca-4f43-8e3a-eae7666c022a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9b4606-c024-429e-9467-06844be0fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "385c2ea0-e470-42b5-84bd-6e05df318049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            hotel_name      city  hotel_cost    restaurant_name  \\\n",
      "0          Hotel Paris     Paris         100           Bistro A   \n",
      "1           Le Meurice     Paris         130        Le Comptoir   \n",
      "2     Hotel Montmartre     Paris          90      Caf de Flore   \n",
      "3           Grand Bali      Bali          80        Warung Bali   \n",
      "4          Ubud Resort      Bali          90             Sarong   \n",
      "..                 ...       ...         ...                ...   \n",
      "58        Hanoi Palace     Hanoi          70       Quan An Ngon   \n",
      "59  Hanoi Garden Hotel     Hanoi          80  Cha Ca Thang Long   \n",
      "60         Cairo Grand     Cairo          75            Sequoia   \n",
      "61     Nile View Hotel     Cairo          90        Abou El Sid   \n",
      "62       Budapest Stay  Budapest          85      New York Caf   \n",
      "\n",
      "    restaurant_cost           attraction_name  attraction_cost  \\\n",
      "0                25              Eiffel Tower               10   \n",
      "1                30             Louvre Museum               12   \n",
      "2                20                Sacr-Cur                8   \n",
      "3                15        Ubud Monkey Forest                8   \n",
      "4                20  Tegallalang Rice Terrace               10   \n",
      "..              ...                       ...              ...   \n",
      "58               20            Hoan Kiem Lake               10   \n",
      "59               25         One Pillar Pagoda               15   \n",
      "60               25          Pyramids of Giza               15   \n",
      "61               30           Egyptian Museum               20   \n",
      "62               28               Buda Castle               12   \n",
      "\n",
      "    transportation_cost  Pool  WiFi  Gym  Breakfast  \n",
      "0                    15     0     1    0        0.0  \n",
      "1                    15     0     1    0        0.0  \n",
      "2                    10     0     1    0        0.0  \n",
      "3                    10     1     0    0        0.0  \n",
      "4                    12     1     1    0        1.0  \n",
      "..                  ...   ...   ...  ...        ...  \n",
      "58                    8     0     1    0        0.0  \n",
      "59                   10     0     1    0        0.0  \n",
      "60                   12     0     1    0        0.0  \n",
      "61                   15     1     1    0        1.0  \n",
      "62                   10     0     1    0        NaN  \n",
      "\n",
      "[63 rows x 12 columns]\n",
      "            hotel_name      city  \\\n",
      "0          Hotel Paris     Paris   \n",
      "1           Le Meurice     Paris   \n",
      "2     Hotel Montmartre     Paris   \n",
      "3           Grand Bali      Bali   \n",
      "4          Ubud Resort      Bali   \n",
      "..                 ...       ...   \n",
      "58        Hanoi Palace     Hanoi   \n",
      "59  Hanoi Garden Hotel     Hanoi   \n",
      "60         Cairo Grand     Cairo   \n",
      "61     Nile View Hotel     Cairo   \n",
      "62       Budapest Stay  Budapest   \n",
      "\n",
      "                                         cleaned_text  \n",
      "0   The Hotel Paris in Paris costs 100 per night. ...  \n",
      "1   The Le Meurice in Paris costs 130 per night. I...  \n",
      "2   The Hotel Montmartre in Paris costs 90 per nig...  \n",
      "3   The Grand Bali in Bali costs 80 per night. It ...  \n",
      "4   The Ubud Resort in Bali costs 90 per night. It...  \n",
      "..                                                ...  \n",
      "58  The Hanoi Palace in Hanoi costs 70 per night. ...  \n",
      "59  The Hanoi Garden Hotel in Hanoi costs 80 per n...  \n",
      "60  The Cairo Grand in Cairo costs 75 per night. I...  \n",
      "61  The Nile View Hotel in Cairo costs 90 per nigh...  \n",
      "62  The Budapest Stay in Budapest costs 85 per nig...  \n",
      "\n",
      "[63 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Convert the structured data into a DataFrame\n",
    "df = pd.read_csv('data.csv')\n",
    "print(df)\n",
    "\n",
    "# Function to preprocess structured fields to align with chatbot intent recognition\n",
    "def preprocess_data(row):\n",
    "    # Create a textual description of each entry\n",
    "    description = f\"The {row['hotel_name']} in {row['city']} costs {row['hotel_cost']} per night. \"\n",
    "    description += f\"It has a restaurant named {row['restaurant_name']} with meals averaging {row['restaurant_cost']} per person. \"\n",
    "    description += f\"Nearby attractions include {row['attraction_name']} with an entry fee of {row['attraction_cost']}. \"\n",
    "    description += f\"Transportation costs approximately {row['transportation_cost']} to get around. \"\n",
    "    \n",
    "    # Mention facilities\n",
    "    if row['Pool']:\n",
    "        description += \"The hotel has a pool. \"\n",
    "    if row['WiFi']:\n",
    "        description += \"Free WiFi is available. \"\n",
    "    if row['Gym']:\n",
    "        description += \"There is a gym. \"\n",
    "    if row['Breakfast']:\n",
    "        description += \"Breakfast is included. \"\n",
    "    \n",
    "    return description.strip()\n",
    "\n",
    "# Apply preprocessing to create text descriptions\n",
    "df['cleaned_text'] = df.apply(preprocess_data, axis=1)\n",
    "\n",
    "# Display the cleaned dataset with generated text\n",
    "print(df[['hotel_name', 'city', 'cleaned_text']])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ed3d62-3b44-42d6-98fd-1c6db3dda46d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "         hotel_name   city  hotel_cost restaurant_name  restaurant_cost  \\\n",
      "0       Hotel Paris  Paris         100        Bistro A               25   \n",
      "1        Le Meurice  Paris         130     Le Comptoir               30   \n",
      "2  Hotel Montmartre  Paris          90   Caf de Flore               20   \n",
      "3        Grand Bali   Bali          80     Warung Bali               15   \n",
      "4       Ubud Resort   Bali          90          Sarong               20   \n",
      "\n",
      "            attraction_name  attraction_cost  transportation_cost  Pool  WiFi  \\\n",
      "0              Eiffel Tower               10                   15     0     1   \n",
      "1             Louvre Museum               12                   15     0     1   \n",
      "2                Sacr-Cur                8                   10     0     1   \n",
      "3        Ubud Monkey Forest                8                   10     1     0   \n",
      "4  Tegallalang Rice Terrace               10                   12     1     1   \n",
      "\n",
      "   Gym  Breakfast  \n",
      "0    0        0.0  \n",
      "1    0        0.0  \n",
      "2    0        0.0  \n",
      "3    0        0.0  \n",
      "4    0        1.0  \n",
      "Welcome to the Hotel Information Chatbot!\n",
      "You can ask about hotels, restaurants, and attractions.\n",
      "Type 'exit' to end the conversation.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  best hotel in paris\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: **Hotel Paris** in Paris costs $100 per night.\n",
      "It has a restaurant named Bistro A with meals averaging $25 per person.\n",
      "Nearby attraction: **Eiffel Tower**, entry fee: $10.\n",
      "Transportation costs approximately $15 to get around.\n",
      "Facilities: WiFi.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 155\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Start the chatbot\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 155\u001b[0m     chat()\n",
      "Cell \u001b[1;32mIn[5], line 144\u001b[0m, in \u001b[0;36mchat\u001b[1;34m()\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to end the conversation.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatbot: Goodbye! Have a great day!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Original Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Function to preprocess structured fields to align with chatbot intent recognition\n",
    "def preprocess_data(row):\n",
    "    description = f\"{row['hotel_name']} in {row['city']} costs {row['hotel_cost']} per night. \"\n",
    "    description += f\"It has a restaurant named {row['restaurant_name']} with meals averaging {row['restaurant_cost']} per person. \"\n",
    "    description += f\"Nearby attractions include {row['attraction_name']} with an entry fee of {row['attraction_cost']}. \"\n",
    "    description += f\"Transportation costs approximately {row['transportation_cost']} to get around. \"\n",
    "    \n",
    "    # Mention facilities\n",
    "    if row['Pool']:\n",
    "        description += \"The hotel has a pool. \"\n",
    "    if row['WiFi']:\n",
    "        description += \"Free WiFi is available. \"\n",
    "    if row['Gym']:\n",
    "        description += \"There is a gym. \"\n",
    "    if row['Breakfast']:\n",
    "        description += \"Breakfast is included. \"\n",
    "    \n",
    "    return description.strip()\n",
    "\n",
    "# Apply preprocessing to create text descriptions\n",
    "df['cleaned_text'] = df.apply(preprocess_data, axis=1)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer for semantic similarity\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Function to get the most similar entry based on the user input\n",
    "def get_most_similar_entry(user_input):\n",
    "    user_input_tfidf = vectorizer.transform([user_input])\n",
    "    similarities = cosine_similarity(user_input_tfidf, tfidf_matrix)\n",
    "    most_similar_index = np.argmax(similarities)\n",
    "    return df.iloc[most_similar_index]\n",
    "\n",
    "# Define Intents\n",
    "INTENTS = {\n",
    "    'greet': {\n",
    "        'keywords': ['hello', 'hi', 'hey', 'good morning', 'good evening']\n",
    "    },\n",
    "    'goodbye': {\n",
    "        'keywords': ['goodbye', 'bye', 'see you', 'thanks', 'thank you']\n",
    "    },\n",
    "    'top_hotel': {\n",
    "        'keywords': ['top hotels', 'best hotels', '5 star hotels', 'top rated hotels']\n",
    "    },\n",
    "    'best_priced_hotel': {\n",
    "        'keywords': ['best priced hotel', 'cheapest hotel', 'lowest cost hotel', 'budget hotel']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to classify intent based on user input\n",
    "def classify_intent(user_input):\n",
    "    user_input_lower = user_input.lower()\n",
    "    for intent, details in INTENTS.items():\n",
    "        for keyword in details['keywords']:\n",
    "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', user_input_lower):\n",
    "                return intent\n",
    "    return 'unknown'\n",
    "\n",
    "# Function to generate a detailed response for hotels, restaurants, or attractions\n",
    "def generate_detailed_response(entry):\n",
    "    response = f\"**{entry['hotel_name']}** in {entry['city']} costs ${entry['hotel_cost']} per night.\\n\"\n",
    "    response += f\"It has a restaurant named {entry['restaurant_name']} with meals averaging ${entry['restaurant_cost']} per person.\\n\"\n",
    "    response += f\"Nearby attraction: **{entry['attraction_name']}**, entry fee: ${entry['attraction_cost']}.\\n\"\n",
    "    response += f\"Transportation costs approximately ${entry['transportation_cost']} to get around.\\n\"\n",
    "    \n",
    "    # Mention facilities\n",
    "    facilities = []\n",
    "    if entry['Pool']:\n",
    "        facilities.append(\"Pool\")\n",
    "    if entry['WiFi']:\n",
    "        facilities.append(\"WiFi\")\n",
    "    if entry['Gym']:\n",
    "        facilities.append(\"Gym\")\n",
    "    if entry['Breakfast']:\n",
    "        facilities.append(\"Breakfast included\")\n",
    "    \n",
    "    if facilities:\n",
    "        response += \"Facilities: \" + \", \".join(facilities) + \".\\n\"\n",
    "    else:\n",
    "        response += \"Facilities: Not specified.\\n\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Function to get the top 5 hotels\n",
    "def get_top_hotel():\n",
    "    top_hotels = df.nlargest(5, 'hotel_cost')[['hotel_name', 'city', 'hotel_cost']]\n",
    "    response = \"Here are the top 5 hotels based on price:\\n\"\n",
    "    for _, row in top_hotels.iterrows():\n",
    "        response += f\"**{row['hotel_name']}** in {row['city']} costs ${row['hotel_cost']} per night.\\n\"\n",
    "    return response\n",
    "\n",
    "# Function to get the best priced hotel\n",
    "def get_best_priced_hotel():\n",
    "    best_hotel = df.nsmallest(1, 'hotel_cost')[['hotel_name', 'city', 'hotel_cost']]\n",
    "    response = \"The best priced hotel is:\\n\"\n",
    "    for _, row in best_hotel.iterrows():\n",
    "        response += f\"**{row['hotel_name']}** in {row['city']} costs ${row['hotel_cost']} per night.\\n\"\n",
    "    return response\n",
    "\n",
    "# Function to handle user input and provide responses\n",
    "def chatbot_response(user_input):\n",
    "    intent = classify_intent(user_input)\n",
    "    \n",
    "    if intent == 'greet':\n",
    "        return \"Hello! How can I assist you today?\"\n",
    "    elif intent == 'goodbye':\n",
    "        return \"Goodbye! Have a great day!\"\n",
    "    elif intent == 'top_hotel':\n",
    "        return get_top_hotel()\n",
    "    elif intent == 'best_priced_hotel':\n",
    "        return get_best_priced_hotel()\n",
    "    \n",
    "    # If intent is unknown, search for the most similar entry\n",
    "    similar_entry = get_most_similar_entry(user_input)\n",
    "    \n",
    "    return generate_detailed_response(similar_entry)\n",
    "\n",
    "# Example conversation loop\n",
    "def chat():\n",
    "    print(\"Welcome to the Hotel Information Chatbot!\")\n",
    "    print(\"You can ask about hotels, restaurants, and attractions.\")\n",
    "    print(\"Type 'exit' to end the conversation.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "        \n",
    "        response = chatbot_response(user_input)\n",
    "        print(f\"Chatbot: {response}\\n\")\n",
    "\n",
    "# Start the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33a22a-1a6e-401e-8fcf-974668b7527e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d34afb78-5ab7-4827-819a-77b383d4cd7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hotel_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hotel_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m description\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Apply preprocessing to create text descriptions\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(preprocess_data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Initialize BERT tokenizer and model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[16], line 19\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_data\u001b[39m(row):\n\u001b[1;32m---> 19\u001b[0m     description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhotel_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m located at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m costs Rs\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m per night.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m     description \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m About: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabout\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m description\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hotel_name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from collections import Counter\n",
    "\n",
    "# Load hotel dataset (update the path)\n",
    "df = pd.read_csv('new_hotel_data.csv')\n",
    "\n",
    "# Function to preprocess structured fields\n",
    "def preprocess_data(row):\n",
    "    description = f\"{row['hotel_name']} located at {row['address']} in {row['city']} costs Rs{row['price']} per night.\"\n",
    "    description += f\" About: {row['about']}.\"\n",
    "    return description.strip()\n",
    "\n",
    "# Apply preprocessing to create text descriptions\n",
    "df['cleaned_text'] = df.apply(preprocess_data, axis=1)\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# Prepare labeled data for intent classification\n",
    "intents_data = [\n",
    "    (\"hello\", \"greet\"),\n",
    "    (\"hi\", \"greet\"),\n",
    "    (\"best hotel in Paris\", \"best_hotel\"),\n",
    "    (\"cheapest hotel\", \"best_priced_hotel\"),\n",
    "    (\"goodbye\", \"goodbye\"),\n",
    "    (\"thanks\", \"goodbye\"),\n",
    "    # Add more training data as needed\n",
    "]\n",
    "\n",
    "# Create DataFrame for intents\n",
    "intents_df = pd.DataFrame(intents_data, columns=[\"user_input\", \"intent\"])\n",
    "\n",
    "# Split data into features and target\n",
    "X = intents_df['user_input']\n",
    "y = intents_df['intent']\n",
    "\n",
    "# Vectorize user inputs using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifiers\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to classify intent using multiple models and a voting mechanism\n",
    "def classify_intent(user_input):\n",
    "    user_input_vectorized = vectorizer.transform([user_input])\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    logistic_prediction = logistic_model.predict(user_input_vectorized)[0]\n",
    "    rf_prediction = random_forest_model.predict(user_input_vectorized)[0]\n",
    "    svm_prediction = svm_model.predict(user_input_vectorized)[0]\n",
    "    \n",
    "    # Use majority voting to determine the final intent\n",
    "    predictions = [logistic_prediction, rf_prediction, svm_prediction]\n",
    "    final_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "    \n",
    "    return final_prediction\n",
    "\n",
    "# Function to get the best hotel in a specific city\n",
    "def get_best_hotel_in_city(city):\n",
    "    best_hotel = df[df['city'].str.lower() == city.lower()].nlargest(1, 'price')\n",
    "    if not best_hotel.empty:\n",
    "        return best_hotel.iloc[0]\n",
    "    return None\n",
    "\n",
    "# Function to generate a detailed response for hotels\n",
    "def generate_detailed_response(entry):\n",
    "    response = f\"**{entry['hotel_name']}** located at {entry['address']} in {entry['city']} costs Rs{entry['price']} per night.\\n\"\n",
    "    response += f\"About: {entry['about']}.\"\n",
    "    return response\n",
    "\n",
    "# Function to handle user input and provide responses\n",
    "def chatbot_response(user_input):\n",
    "    intent = classify_intent(user_input)\n",
    "    \n",
    "    if intent == 'greet':\n",
    "        return \"Hello! How can I assist you today?\"\n",
    "    elif intent == 'goodbye':\n",
    "        return \"Goodbye! Have a great day!\"\n",
    "    elif intent == 'best_hotel':\n",
    "        city = re.findall(r'in (\\w+)', user_input)  # Extract city from user input\n",
    "        if city:\n",
    "            city_name = city[0]\n",
    "            best_hotel_entry = get_best_hotel_in_city(city_name)\n",
    "            if best_hotel_entry is not None:\n",
    "                return generate_detailed_response(best_hotel_entry)\n",
    "            else:\n",
    "                return f\"Sorry, I couldn't find any hotels in {city_name}.\"\n",
    "    \n",
    "    elif intent == 'best_priced_hotel':\n",
    "        return get_best_priced_hotel()\n",
    "    \n",
    "    # If intent is unknown, respond accordingly\n",
    "    return \"I'm sorry, I didn't understand your request.\"\n",
    "\n",
    "# Example conversation loop\n",
    "def chat():\n",
    "    print(\"Welcome to the Hotel Information Chatbot!\")\n",
    "    print(\"You can ask about hotels in different cities.\")\n",
    "    print(\"Type 'exit' to end the conversation.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "        \n",
    "        response = chatbot_response(user_input)\n",
    "        print(f\"Chatbot: {response}\\n\")\n",
    "\n",
    "# Start the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f3f28-62ac-427b-b9f7-0a4d270a1d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43943452-10fc-49b4-be48-3bc6047ca638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "\n",
    "# Load the hotel dataset (update the file path accordingly)\n",
    "df = pd.read_csv('new_hotel_data.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Original Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Function to preprocess structured fields to align with chatbot intent recognition\n",
    "def preprocess_data(row):\n",
    "    name = row['name']\n",
    "    address = row['address']\n",
    "    price = row['price']\n",
    "    city = row['city']\n",
    "    about = row['about']\n",
    "    description = f\"{name}, located at {address}, in {city} costs Rs{price} per night. About: {about}.\"\n",
    "    return description.strip()\n",
    "\n",
    "# Apply preprocessing to create text descriptions\n",
    "df['cleaned_text'] = df.apply(preprocess_data, axis=1)\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Generate BERT embeddings for hotel descriptions\n",
    "df['embeddings'] = df['cleaned_text'].apply(get_bert_embeddings)\n",
    "\n",
    "# Function to get the most similar entry based on the user input\n",
    "def get_most_similar_entry(user_input):\n",
    "    user_input_embedding = get_bert_embeddings(user_input)\n",
    "    similarities = cosine_similarity([user_input_embedding], list(df['embeddings'].values))\n",
    "    most_similar_index = np.argmax(similarities)\n",
    "    return df.iloc[most_similar_index]\n",
    "\n",
    "# Define Intents\n",
    "INTENTS = {\n",
    "    'greet': {'keywords': ['hello', 'hi', 'hey', 'good morning', 'good evening']},\n",
    "    'goodbye': {'keywords': ['goodbye', 'bye', 'see you', 'thanks', 'thank you']},\n",
    "    'top_hotel': {'keywords': ['top hotels', 'best hotels', '5 star hotels', 'top rated hotels']},\n",
    "    'best_priced_hotel': {'keywords': ['best priced hotel', 'cheapest hotel', 'lowest cost hotel', 'budget hotel']}\n",
    "}\n",
    "\n",
    "# Function to classify intent based on user input\n",
    "def classify_intent(user_input):\n",
    "    user_input_lower = user_input.lower()\n",
    "    for intent, details in INTENTS.items():\n",
    "        for keyword in details['keywords']:\n",
    "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', user_input_lower):\n",
    "                return intent\n",
    "    return 'unknown'\n",
    "\n",
    "# Function to extract the number from user input for top hotels\n",
    "def extract_number(user_input):\n",
    "    numbers = re.findall(r'\\d+', user_input)\n",
    "    return int(numbers[0]) if numbers else 5  # Default to 5 if no number is found\n",
    "\n",
    "# Function to generate a detailed response for hotels\n",
    "def generate_detailed_response(entry):\n",
    "    response = f\"**{entry['name']}** located at {entry['address']} in {entry['city']} costs Rs{entry['price']} per night.\"\n",
    "    return response\n",
    "\n",
    "# Function to get the top N hotels\n",
    "def get_top_hotel(n=5):\n",
    "    top_hotels = df.nlargest(n, 'price')[['name', 'city', 'price']]\n",
    "    response = f\"Here are the top {n} hotels based on price:\\n\"\n",
    "    for _, row in top_hotels.iterrows():\n",
    "        response += f\"**{row['name']}** in {row['city']} costs Rs{row['price']} per night.\\n\"\n",
    "    return response\n",
    "\n",
    "# Function to get the best priced hotel\n",
    "def get_best_priced_hotel():\n",
    "    best_hotel = df.nsmallest(1, 'price')[['name', 'city', 'price']]\n",
    "    response = \"The best priced hotel is:\\n\"\n",
    "    for _, row in best_hotel.iterrows():\n",
    "        response += f\"**{row['name']}** in {row['city']} costs Rs{row['price']} per night.\\n\"\n",
    "    return response\n",
    "\n",
    "# Function to handle user input and provide responses\n",
    "def chatbot_response(user_input):\n",
    "    intent = classify_intent(user_input)\n",
    "    \n",
    "    if intent == 'greet':\n",
    "        return \"Hello! How can I assist you with hotel information today?\"\n",
    "    elif intent == 'goodbye':\n",
    "        return \"Goodbye! Have a great day!\"\n",
    "    elif intent == 'top_hotel':\n",
    "        n = extract_number(user_input)\n",
    "        return get_top_hotel(n)\n",
    "    elif intent == 'best_priced_hotel':\n",
    "        return get_best_priced_hotel()\n",
    "    \n",
    "    similar_entry = get_most_similar_entry(user_input)\n",
    "    return generate_detailed_response(similar_entry)\n",
    "\n",
    "# Example conversation loop\n",
    "def chat():\n",
    "    print(\"Welcome to the Hotel Information Chatbot!\")\n",
    "    print(\"You can ask about hotels.\")\n",
    "    print(\"Type 'exit' to end the conversation.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "        \n",
    "        response = chatbot_response(user_input)\n",
    "        print(f\"Chatbot: {response}\\n\")\n",
    "\n",
    "# Start the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        chat()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc0b50-7ab8-4f67-970a-672c12e1ec64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd70a4c-b75a-4b6b-9bd5-02257b59e3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "         hotel_name   city  hotel_cost restaurant_name  restaurant_cost  \\\n",
      "0       Hotel Paris  Paris         100        Bistro A               25   \n",
      "1        Le Meurice  Paris         130     Le Comptoir               30   \n",
      "2  Hotel Montmartre  Paris          90   Caf de Flore               20   \n",
      "3        Grand Bali   Bali          80     Warung Bali               15   \n",
      "4       Ubud Resort   Bali          90          Sarong               20   \n",
      "\n",
      "            attraction_name  attraction_cost  transportation_cost  Pool  WiFi  \\\n",
      "0              Eiffel Tower               10                   15     0     1   \n",
      "1             Louvre Museum               12                   15     0     1   \n",
      "2                Sacr-Cur                8                   10     0     1   \n",
      "3        Ubud Monkey Forest                8                   10     1     0   \n",
      "4  Tegallalang Rice Terrace               10                   12     1     1   \n",
      "\n",
      "   Gym  Breakfast  \n",
      "0    0        0.0  \n",
      "1    0        0.0  \n",
      "2    0        0.0  \n",
      "3    0        0.0  \n",
      "4    0        1.0  \n",
      "Welcome to the Hotel Information Chatbot!\n",
      "You can ask about hotels, restaurants, and attractions.\n",
      "Type 'exit' to end the conversation.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  best hotel in paris\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: **Hotel Montmartre** in Paris costs $90 per night.\n",
      "It has a restaurant named **Caf de Flore** with meals averaging $20 per person.\n",
      "Nearby attraction: **Sacr-Cur**, entry fee: $8.\n",
      "Transportation costs approximately $10 to get around.\n",
      "Facilities: Free WiFi.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 154\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# Start the chatbot\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 154\u001b[0m     chat()\n",
      "Cell \u001b[1;32mIn[4], line 143\u001b[0m, in \u001b[0;36mchat\u001b[1;34m()\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to end the conversation.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatbot: Goodbye! Have a great day!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Original Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Initialize BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# Function to preprocess structured fields to align with chatbot intent recognition\n",
    "def preprocess_data(row):\n",
    "    description = f\"{row['hotel_name']} in {row['city']} costs ${row['hotel_cost']} per night. \"\n",
    "    description += f\"It has a restaurant named {row['restaurant_name']} with meals averaging ${row['restaurant_cost']} per person. \"\n",
    "    description += f\"Nearby attractions include {row['attraction_name']} with an entry fee of ${row['attraction_cost']}. \"\n",
    "    description += f\"Transportation costs approximately ${row['transportation_cost']} to get around. \"\n",
    "    \n",
    "    # Mention facilities\n",
    "    facilities = []\n",
    "    if row['Pool']:\n",
    "        facilities.append(\"Pool\")\n",
    "    if row['WiFi']:\n",
    "        facilities.append(\"Free WiFi\")\n",
    "    if row['Gym']:\n",
    "        facilities.append(\"Gym\")\n",
    "    if row['Breakfast']:\n",
    "        facilities.append(\"Breakfast included\")\n",
    "    \n",
    "    description += \"Facilities: \" + \", \".join(facilities) + \".\"\n",
    "    \n",
    "    return description.strip()\n",
    "\n",
    "# Apply preprocessing to create text descriptions\n",
    "df['cleaned_text'] = df.apply(preprocess_data, axis=1)\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Ensure it returns a 2D numpy array\n",
    "\n",
    "# Create embeddings for the dataset\n",
    "embedding_matrix = np.vstack([get_bert_embeddings(text) for text in df['cleaned_text']])\n",
    "\n",
    "# Function to get the most similar entry based on the user input using BERT embeddings\n",
    "def get_most_similar_entry(user_input):\n",
    "    user_input_embedding = get_bert_embeddings(user_input).reshape(1, -1)  # Reshape to 2D\n",
    "    similarities = cosine_similarity(user_input_embedding, embedding_matrix)\n",
    "    most_similar_index = np.argmax(similarities)\n",
    "    return df.iloc[most_similar_index]\n",
    "\n",
    "# Define Intents\n",
    "INTENTS = {\n",
    "    'greet': {\n",
    "        'keywords': ['hello', 'hi', 'hey', 'good morning', 'good evening']\n",
    "    },\n",
    "    'goodbye': {\n",
    "        'keywords': ['goodbye', 'bye', 'see you', 'thanks', 'thank you']\n",
    "    },\n",
    "    'best_hotel': {\n",
    "        'keywords': ['best hotel', 'top hotel', '5 star hotel', 'highest rated hotel', 'best priced hotel']\n",
    "    },\n",
    "    'best_priced_hotel': {\n",
    "        'keywords': ['cheapest hotel', 'lowest cost hotel', 'budget hotel']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to classify intent based on user input\n",
    "def classify_intent(user_input):\n",
    "    user_input_lower = user_input.lower()\n",
    "    for intent, details in INTENTS.items():\n",
    "        for keyword in details['keywords']:\n",
    "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', user_input_lower):\n",
    "                return intent\n",
    "    return 'unknown'\n",
    "\n",
    "# Function to generate a detailed response for hotels, restaurants, or attractions\n",
    "def generate_detailed_response(entry):\n",
    "    response = f\"**{entry['hotel_name']}** in {entry['city']} costs ${entry['hotel_cost']} per night.\\n\"\n",
    "    response += f\"It has a restaurant named **{entry['restaurant_name']}** with meals averaging ${entry['restaurant_cost']} per person.\\n\"\n",
    "    response += f\"Nearby attraction: **{entry['attraction_name']}**, entry fee: ${entry['attraction_cost']}.\\n\"\n",
    "    response += f\"Transportation costs approximately ${entry['transportation_cost']} to get around.\\n\"\n",
    "    response += f\"Facilities: {', '.join(['Pool' if entry['Pool'] else '', 'Free WiFi' if entry['WiFi'] else '', 'Gym' if entry['Gym'] else '', 'Breakfast included' if entry['Breakfast'] else '']).strip(', ')}.\\n\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Function to get the best hotel in a specific city\n",
    "def get_best_hotel_in_city(city):\n",
    "    best_hotel = df[df['city'].str.lower() == city.lower()].nsmallest(1, 'hotel_cost')\n",
    "    if not best_hotel.empty:\n",
    "        return best_hotel.iloc[0]\n",
    "    return None\n",
    "\n",
    "# Function to handle user input and provide responses\n",
    "def chatbot_response(user_input):\n",
    "    intent = classify_intent(user_input)\n",
    "    \n",
    "    if intent == 'greet':\n",
    "        return \"Hello! How can I assist you today?\"\n",
    "    elif intent == 'goodbye':\n",
    "        return \"Goodbye! Have a great day!\"\n",
    "    elif intent == 'best_hotel':\n",
    "        city = re.findall(r'in (\\w+)', user_input)  # Extract city from user input\n",
    "        if city:\n",
    "            city_name = city[0]\n",
    "            best_hotel_entry = get_best_hotel_in_city(city_name)\n",
    "            if best_hotel_entry is not None:\n",
    "                return generate_detailed_response(best_hotel_entry)\n",
    "            else:\n",
    "                return f\"Sorry, I couldn't find any hotels in {city_name}.\"\n",
    "    \n",
    "    elif intent == 'best_priced_hotel':\n",
    "        return get_best_priced_hotel()\n",
    "    \n",
    "    # If intent is unknown, search for the most similar entry\n",
    "    similar_entry = get_most_similar_entry(user_input)\n",
    "    \n",
    "    return generate_detailed_response(similar_entry)\n",
    "\n",
    "# Example conversation loop\n",
    "def chat():\n",
    "    print(\"Welcome to the Hotel Information Chatbot!\")\n",
    "    print(\"You can ask about hotels, restaurants, and attractions.\")\n",
    "    print(\"Type 'exit' to end the conversation.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "        \n",
    "        response = chatbot_response(user_input)\n",
    "        print(f\"Chatbot: {response}\\n\")\n",
    "\n",
    "# Start the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cfb58a2-3f65-44d9-8a53-453dac416acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/44.4 kB 330.3 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 41.0/44.4 kB 326.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.4/44.4 kB 363.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Using cached huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.0-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
      "Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/9.9 MB 3.4 MB/s eta 0:00:03\n",
      "   ---------------------------------------- 0.1/9.9 MB 1.1 MB/s eta 0:00:10\n",
      "    --------------------------------------- 0.2/9.9 MB 1.6 MB/s eta 0:00:07\n",
      "    --------------------------------------- 0.2/9.9 MB 1.7 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.3/9.9 MB 1.5 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.4/9.9 MB 1.7 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/9.9 MB 1.8 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.5/9.9 MB 1.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.6/9.9 MB 1.6 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.7/9.9 MB 1.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.8/9.9 MB 1.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.8/9.9 MB 1.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.9/9.9 MB 1.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.0/9.9 MB 1.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.1/9.9 MB 1.6 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.1/9.9 MB 1.5 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.2/9.9 MB 1.5 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.3/9.9 MB 1.5 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.4/9.9 MB 1.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.4/9.9 MB 1.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.5/9.9 MB 1.5 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.6/9.9 MB 1.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.7/9.9 MB 1.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.8/9.9 MB 1.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.9/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.9/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.0/9.9 MB 1.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.1/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.2/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.3/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.4/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.5/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.5/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.6/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.7/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.8/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.9/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 2.9/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.0/9.9 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.1/9.9 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.3/9.9 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.4/9.9 MB 1.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.5/9.9 MB 1.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.6/9.9 MB 1.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.6/9.9 MB 1.8 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.8/9.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.0/9.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.1/9.9 MB 1.9 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.1/9.9 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.4/9.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.5/9.9 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.7/9.9 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 4.8/9.9 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.0/9.9 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.1/9.9 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.3/9.9 MB 2.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.4/9.9 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.7/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.9/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.0/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.1/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.3/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.3/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.3/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.4/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.6/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.8/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.8/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.9/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.0/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.1/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.2/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.2/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.2/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.2/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.4/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.5/9.9 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.6/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.8/9.9 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.0/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.0/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.1/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.3/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.4/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.6/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.7/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.7/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.8/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.9/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.0/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.2/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.3/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.5/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.6/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.9 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/9.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 2.1 MB/s eta 0:00:00\n",
      "Using cached huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.3 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 143.4/286.3 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 286.3/286.3 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.20.0-cp312-none-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/2.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.3 MB 3.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.7/2.3 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.9/2.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.0/2.3 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.3 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.5/2.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.7/2.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.0/2.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.2/2.3 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.2/2.3 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.25.1 safetensors-0.4.5 tokenizers-0.20.0 transformers-4.45.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed99099c-a9a4-4112-8990-b6559ba0aa34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\aamir\\anaconda3\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipywidgets) (3.6.6)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipywidgets) (8.25.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.6.6->ipywidgets) (7.0.8)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.25.1)\n",
      "Requirement already satisfied: jupyterlab<4.1,>=4.0.2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (3.1.4)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (7.10.0)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (5.9.2)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (7.4.0)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (23.2)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.10)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (6.28.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.19.2)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.32.2)\n",
      "Requirement already satisfied: six in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from asttokens->stack-data->ipython>=4.0.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from babel>=2.10->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2024.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (305.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2024.6.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipykernel->jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipykernel->jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from ipykernel->jupyterlab<4.1,>=4.0.2->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.5.1)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets)\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets)\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.1)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets)\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=1.11 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets)\n",
      "  Downloading webcolors-24.8.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.2.3)\n",
      "Downloading webcolors-24.8.0-py3-none-any.whl (15 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webcolors, uri-template, fqdn, isoduration\n",
      "Successfully installed fqdn-1.5.1 isoduration-20.11.0 uri-template-1.3.0 webcolors-24.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda947f-bf51-4824-b677-cbc73ee2abd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca3db7-989c-422d-a9ec-409253c328f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "         hotel_name   city  hotel_cost restaurant_name  restaurant_cost  \\\n",
      "0       Hotel Paris  Paris         100        Bistro A               25   \n",
      "1        Le Meurice  Paris         130     Le Comptoir               30   \n",
      "2  Hotel Montmartre  Paris          90   Caf de Flore               20   \n",
      "3        Grand Bali   Bali          80     Warung Bali               15   \n",
      "4       Ubud Resort   Bali          90          Sarong               20   \n",
      "\n",
      "            attraction_name  attraction_cost  transportation_cost  Pool  WiFi  \\\n",
      "0              Eiffel Tower               10                   15     0     1   \n",
      "1             Louvre Museum               12                   15     0     1   \n",
      "2                Sacr-Cur                8                   10     0     1   \n",
      "3        Ubud Monkey Forest                8                   10     1     0   \n",
      "4  Tegallalang Rice Terrace               10                   12     1     1   \n",
      "\n",
      "   Gym  Breakfast  \n",
      "0    0        0.0  \n",
      "1    0        0.0  \n",
      "2    0        0.0  \n",
      "3    0        0.0  \n",
      "4    0        1.0  \n",
      "Welcome to the Hotel Information Chatbot!\n",
      "You can ask about hotels, restaurants, and attractions.\n",
      "Type 'exit' to end the conversation.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  best hotel in bali\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: **Grand Bali** in **Bali** costs **$80** per night.\n",
      "It has a restaurant named **Warung Bali** with meals averaging **$15** per person.\n",
      "Nearby attraction: **Ubud Monkey Forest**, entry fee: **$8**.\n",
      "Transportation costs approximately **$10** to get around.\n",
      "Facilities: **Pool**.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Initialize BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# Function to preprocess structured fields to align with chatbot intent recognition\n",
    "def preprocess_data(row):\n",
    "    description = f\"{row['hotel_name']} in {row['city']} costs ${row['hotel_cost']} per night. \"\n",
    "    description += f\"It has a restaurant named {row['restaurant_name']} with meals averaging ${row['restaurant_cost']} per person. \"\n",
    "    description += f\"Nearby attractions include {row['attraction_name']} with an entry fee of ${row['attraction_cost']}. \"\n",
    "    description += f\"Transportation costs approximately ${row['transportation_cost']} to get around. \"\n",
    "    \n",
    "    # Mention facilities\n",
    "    facilities = []\n",
    "    if row['Pool']:\n",
    "        facilities.append(\"Pool\")\n",
    "    if row['WiFi']:\n",
    "        facilities.append(\"Free WiFi\")\n",
    "    if row['Gym']:\n",
    "        facilities.append(\"Gym\")\n",
    "    if row['Breakfast']:\n",
    "        facilities.append(\"Breakfast included\")\n",
    "    \n",
    "    description += \" Facilities: \" + \", \".join(facilities) + \".\"\n",
    "    \n",
    "    return description.strip()\n",
    "\n",
    "# Apply preprocessing to create text descriptions\n",
    "df['cleaned_text'] = df.apply(preprocess_data, axis=1)\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Ensure it returns a 2D numpy array\n",
    "\n",
    "# Create embeddings for the dataset\n",
    "embedding_matrix = np.vstack([get_bert_embeddings(text) for text in df['cleaned_text']])\n",
    "\n",
    "# Function to get the most similar entry based on the user input using BERT embeddings\n",
    "def get_most_similar_entry(user_input):\n",
    "    user_input_embedding = get_bert_embeddings(user_input).reshape(1, -1)  # Reshape to 2D\n",
    "    similarities = cosine_similarity(user_input_embedding, embedding_matrix)\n",
    "    most_similar_index = np.argmax(similarities)\n",
    "    return df.iloc[most_similar_index]\n",
    "\n",
    "# Define Intents\n",
    "INTENTS = {\n",
    "    'greet': {\n",
    "        'keywords': ['hello', 'hi', 'hey', 'good morning', 'good evening']\n",
    "    },\n",
    "    'goodbye': {\n",
    "        'keywords': ['goodbye', 'bye', 'see you', 'thanks', 'thank you']\n",
    "    },\n",
    "    'best_hotel': {\n",
    "        'keywords': ['best hotel', 'top hotel', '5 star hotel', 'highest rated hotel', 'best priced hotel']\n",
    "    },\n",
    "    'best_priced_hotel': {\n",
    "        'keywords': ['cheapest hotel', 'lowest cost hotel', 'budget hotel']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to classify intent based on user input\n",
    "def classify_intent(user_input):\n",
    "    user_input_lower = user_input.lower()\n",
    "    for intent, details in INTENTS.items():\n",
    "        for keyword in details['keywords']:\n",
    "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', user_input_lower):\n",
    "                return intent\n",
    "    return 'unknown'\n",
    "\n",
    "# Function to generate a detailed response for hotels, restaurants, or attractions\n",
    "def generate_detailed_response(entry):\n",
    "    response = f\"**{entry['hotel_name']}** in **{entry['city']}** costs **${entry['hotel_cost']}** per night.\\n\"\n",
    "    response += f\"It has a restaurant named **{entry['restaurant_name']}** with meals averaging **${entry['restaurant_cost']}** per person.\\n\"\n",
    "    response += f\"Nearby attraction: **{entry['attraction_name']}**, entry fee: **${entry['attraction_cost']}**.\\n\"\n",
    "    response += f\"Transportation costs approximately **${entry['transportation_cost']}** to get around.\\n\"\n",
    "    \n",
    "    facilities = []\n",
    "    if entry['Pool']:\n",
    "        facilities.append(\"Pool\")\n",
    "    if entry['WiFi']:\n",
    "        facilities.append(\"Free WiFi\")\n",
    "    if entry['Gym']:\n",
    "        facilities.append(\"Gym\")\n",
    "    if entry['Breakfast']:\n",
    "        facilities.append(\"Breakfast included\")\n",
    "    \n",
    "    if facilities:\n",
    "        response += f\"Facilities: **{', '.join(facilities)}**.\\n\"\n",
    "    else:\n",
    "        response += \"Facilities: Not specified.\\n\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Function to get the best hotel in a specific city\n",
    "def get_best_hotel_in_city(city):\n",
    "    best_hotel = df[df['city'].str.lower() == city.lower()].nsmallest(1, 'hotel_cost')\n",
    "    if not best_hotel.empty:\n",
    "        return best_hotel.iloc[0]\n",
    "    return None\n",
    "\n",
    "# Function to handle user input and provide responses\n",
    "def chatbot_response(user_input):\n",
    "    intent = classify_intent(user_input)\n",
    "    \n",
    "    if intent == 'greet':\n",
    "        return \"Hello! How can I assist you today?\"\n",
    "    elif intent == 'goodbye':\n",
    "        return \"Goodbye! Have a great day!\"\n",
    "    elif intent == 'best_hotel':\n",
    "        city = re.search(r'in (\\w+)', user_input)  # Extract city from user input\n",
    "        if city:\n",
    "            city_name = city.group(1)  # Use group() to extract the matched city\n",
    "            best_hotel_entry = get_best_hotel_in_city(city_name)\n",
    "            if best_hotel_entry is not None:\n",
    "                return generate_detailed_response(best_hotel_entry)\n",
    "            else:\n",
    "                return f\"Sorry, I couldn't find any hotels in {city_name}. Please check the city name and try again.\"\n",
    "    \n",
    "    elif intent == 'best_priced_hotel':\n",
    "        return get_best_priced_hotel()\n",
    "    \n",
    "    # If intent is unknown, search for the most similar entry\n",
    "    similar_entry = get_most_similar_entry(user_input)\n",
    "    \n",
    "    return generate_detailed_response(similar_entry)\n",
    "\n",
    "# Example conversation loop\n",
    "def chat():\n",
    "    print(\"Welcome to the Hotel Information Chatbot!\")\n",
    "    print(\"You can ask about hotels, restaurants, and attractions.\")\n",
    "    print(\"Type 'exit' to end the conversation.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "        \n",
    "        response = chatbot_response(user_input)\n",
    "        print(f\"Chatbot: {response}\\n\")\n",
    "\n",
    "# Start the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad7f3ab3-e180-4521-b5f7-a59e75606368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>images</th>\n",
       "      <th>price</th>\n",
       "      <th>city</th>\n",
       "      <th>about</th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>Sleeps 3</th>\n",
       "      <th>4 beds</th>\n",
       "      <th>...</th>\n",
       "      <th>3 bedrooms</th>\n",
       "      <th>33 sq m</th>\n",
       "      <th>Sleeps 7</th>\n",
       "      <th>Indoor pool</th>\n",
       "      <th>Sleeps 29</th>\n",
       "      <th>Cot</th>\n",
       "      <th>47 sq m</th>\n",
       "      <th>Wheelchair accessible</th>\n",
       "      <th>56 sq m</th>\n",
       "      <th>186 sq m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'$oid': '66bc7a8c0c64f6180de0d84f'}</td>\n",
       "      <td>Midway Residency</td>\n",
       "      <td>3rd Floor App 301, 143-A Sector, Sector C Comm...</td>\n",
       "      <td>[https://lh6.googleusercontent.com/proxy/Yu51c...</td>\n",
       "      <td>12648</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>Check-out time: 12:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'$oid': '66bc7ab70c64f6180de0d850'}</td>\n",
       "      <td>Hotel Royal Comfort</td>\n",
       "      <td>F788+W9X, opposite Emporium Mall, Trade Centre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5218</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>Perfect for business and leisure travelers.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'$oid': '66bc7adc0c64f6180de0d855'}</td>\n",
       "      <td>hostel view garden</td>\n",
       "      <td>7 Shahrah Aiwan-e-Sanat-o-Tijarat, near china ...</td>\n",
       "      <td>[https://lh5.googleusercontent.com/p/AF1QipMzu...</td>\n",
       "      <td>12648</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>InternetWi-FiPoolsNo poolsNo hot tub</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'$oid': '66bc7b240c64f6180de0d860'}</td>\n",
       "      <td>WEDNESDAY HOMES</td>\n",
       "      <td>address not available</td>\n",
       "      <td>[https://lh5.googleusercontent.com/p/AF1QipP-y...</td>\n",
       "      <td>12648</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>Perfect for business and leisure travelers.</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'$oid': '66bc7b670c64f6180de0d86b'}</td>\n",
       "      <td>Prime Motel</td>\n",
       "      <td>address not available</td>\n",
       "      <td>[https://lh5.googleusercontent.com/p/AF1QipOpg...</td>\n",
       "      <td>12648</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>InternetWi-FifreeServicesFront desk24-hourFull...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>{'$oid': '66c26096720b39c64cc1bf8c'}</td>\n",
       "      <td>Batakundi Eco Hotel</td>\n",
       "      <td>Mansehra - Naran - Jalkhad - Chilas Rd, Bataku...</td>\n",
       "      <td>[https://lh6.googleusercontent.com/proxy/-_rAe...</td>\n",
       "      <td>21724</td>\n",
       "      <td>Batakundi</td>\n",
       "      <td>Check-in time: 14:00Check-out time: 12:00</td>\n",
       "      <td>2302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>{'$oid': '66c260e9720b39c64cc1bfa1'}</td>\n",
       "      <td>PTDC Motels, Naran</td>\n",
       "      <td>WM63+J5C, PTDC Motel Area, Naran, Mansehra, Kh...</td>\n",
       "      <td>[https://lh5.googleusercontent.com/p/AF1QipORx...</td>\n",
       "      <td>12648</td>\n",
       "      <td>Batakundi</td>\n",
       "      <td>Check-out time: 11:00</td>\n",
       "      <td>2303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>{'$oid': '66c2612f720b39c64cc1bfab'}</td>\n",
       "      <td>New Lalazar Hotel</td>\n",
       "      <td>address not available</td>\n",
       "      <td>[https://lh5.googleusercontent.com/p/AF1QipMTz...</td>\n",
       "      <td>12648</td>\n",
       "      <td>Batakundi</td>\n",
       "      <td>Check-out time: 12:00</td>\n",
       "      <td>2304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>{'$oid': '66c26173720b39c64cc1bfb6'}</td>\n",
       "      <td>Rozhok Hotel Naran</td>\n",
       "      <td>WM57+JG, Katha, Naran, Mansehra, Khyber Pakhtu...</td>\n",
       "      <td>[https://lh5.googleusercontent.com/p/AF1QipOWr...</td>\n",
       "      <td>7424</td>\n",
       "      <td>Batakundi</td>\n",
       "      <td>Located in the heart of the city.</td>\n",
       "      <td>2305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>{'$oid': '66c261b7720b39c64cc1bfcb'}</td>\n",
       "      <td>Fairy Meadows Hotel</td>\n",
       "      <td>address not available</td>\n",
       "      <td>[https://lh5.googleusercontent.com/proxy/p6y-T...</td>\n",
       "      <td>20176</td>\n",
       "      <td>Batakundi</td>\n",
       "      <td>Check-in time: 14:00Check-out time: 12:00</td>\n",
       "      <td>2306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3472 rows  178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       _id                 name  \\\n",
       "0     {'$oid': '66bc7a8c0c64f6180de0d84f'}     Midway Residency   \n",
       "1     {'$oid': '66bc7ab70c64f6180de0d850'}  Hotel Royal Comfort   \n",
       "2     {'$oid': '66bc7adc0c64f6180de0d855'}   hostel view garden   \n",
       "3     {'$oid': '66bc7b240c64f6180de0d860'}      WEDNESDAY HOMES   \n",
       "4     {'$oid': '66bc7b670c64f6180de0d86b'}          Prime Motel   \n",
       "...                                    ...                  ...   \n",
       "3467  {'$oid': '66c26096720b39c64cc1bf8c'}  Batakundi Eco Hotel   \n",
       "3468  {'$oid': '66c260e9720b39c64cc1bfa1'}   PTDC Motels, Naran   \n",
       "3469  {'$oid': '66c2612f720b39c64cc1bfab'}    New Lalazar Hotel   \n",
       "3470  {'$oid': '66c26173720b39c64cc1bfb6'}   Rozhok Hotel Naran   \n",
       "3471  {'$oid': '66c261b7720b39c64cc1bfcb'}  Fairy Meadows Hotel   \n",
       "\n",
       "                                                address  \\\n",
       "0     3rd Floor App 301, 143-A Sector, Sector C Comm...   \n",
       "1     F788+W9X, opposite Emporium Mall, Trade Centre...   \n",
       "2     7 Shahrah Aiwan-e-Sanat-o-Tijarat, near china ...   \n",
       "3                                 address not available   \n",
       "4                                 address not available   \n",
       "...                                                 ...   \n",
       "3467  Mansehra - Naran - Jalkhad - Chilas Rd, Bataku...   \n",
       "3468  WM63+J5C, PTDC Motel Area, Naran, Mansehra, Kh...   \n",
       "3469                              address not available   \n",
       "3470  WM57+JG, Katha, Naran, Mansehra, Khyber Pakhtu...   \n",
       "3471                              address not available   \n",
       "\n",
       "                                                 images  price       city  \\\n",
       "0     [https://lh6.googleusercontent.com/proxy/Yu51c...  12648     Lahore   \n",
       "1                                                    []   5218     Lahore   \n",
       "2     [https://lh5.googleusercontent.com/p/AF1QipMzu...  12648     Lahore   \n",
       "3     [https://lh5.googleusercontent.com/p/AF1QipP-y...  12648     Lahore   \n",
       "4     [https://lh5.googleusercontent.com/p/AF1QipOpg...  12648     Lahore   \n",
       "...                                                 ...    ...        ...   \n",
       "3467  [https://lh6.googleusercontent.com/proxy/-_rAe...  21724  Batakundi   \n",
       "3468  [https://lh5.googleusercontent.com/p/AF1QipORx...  12648  Batakundi   \n",
       "3469  [https://lh5.googleusercontent.com/p/AF1QipMTz...  12648  Batakundi   \n",
       "3470  [https://lh5.googleusercontent.com/p/AF1QipOWr...   7424  Batakundi   \n",
       "3471  [https://lh5.googleusercontent.com/proxy/p6y-T...  20176  Batakundi   \n",
       "\n",
       "                                                  about  hotel_id  Sleeps 3  \\\n",
       "0                                 Check-out time: 12:00         1         0   \n",
       "1           Perfect for business and leisure travelers.         2         0   \n",
       "2                  InternetWi-FiPoolsNo poolsNo hot tub         3         0   \n",
       "3           Perfect for business and leisure travelers.         4         0   \n",
       "4     InternetWi-FifreeServicesFront desk24-hourFull...         5         0   \n",
       "...                                                 ...       ...       ...   \n",
       "3467          Check-in time: 14:00Check-out time: 12:00      2302         0   \n",
       "3468                              Check-out time: 11:00      2303         0   \n",
       "3469                              Check-out time: 12:00      2304         0   \n",
       "3470                  Located in the heart of the city.      2305         0   \n",
       "3471          Check-in time: 14:00Check-out time: 12:00      2306         0   \n",
       "\n",
       "      4 beds  ...  3 bedrooms  33 sq m  Sleeps 7  Indoor pool  Sleeps 29  Cot  \\\n",
       "0          0  ...           0        0         0            0          0    0   \n",
       "1          0  ...           0        0         0            0          0    0   \n",
       "2          0  ...           0        0         0            0          0    0   \n",
       "3          0  ...           0        0         0            0          0    0   \n",
       "4          0  ...           0        0         0            0          0    0   \n",
       "...      ...  ...         ...      ...       ...          ...        ...  ...   \n",
       "3467       0  ...           0        0         0            0          0    0   \n",
       "3468       0  ...           0        0         0            0          0    0   \n",
       "3469       0  ...           0        0         0            0          0    0   \n",
       "3470       0  ...           0        0         0            0          0    0   \n",
       "3471       0  ...           0        0         0            0          0    0   \n",
       "\n",
       "      47 sq m  Wheelchair accessible  56 sq m  186 sq m  \n",
       "0           0                      0        0         0  \n",
       "1           0                      0        0         0  \n",
       "2           0                      0        0         0  \n",
       "3           0                      0        0         0  \n",
       "4           0                      0        0         0  \n",
       "...       ...                    ...      ...       ...  \n",
       "3467        0                      0        0         0  \n",
       "3468        0                      0        0         0  \n",
       "3469        0                      0        0         0  \n",
       "3470        0                      0        0         0  \n",
       "3471        0                      0        0         0  \n",
       "\n",
       "[3472 rows x 178 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e39786-fdf7-4728-b15c-6ff56cab7b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7403a896-a00b-490a-8613-b0cc320473c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 12 fields in line 15, saw 13\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the dataset\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 12 fields in line 15, saw 13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Initialize BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# Function to preprocess structured fields to align with chatbot intent recognition\n",
    "def preprocess_data(row):\n",
    "    description = f\"{row['hotel_name']} in {row['city']} costs ${row['hotel_cost']} per night. \"\n",
    "    description += f\"It has a restaurant named {row['restaurant_name']} with meals averaging ${row['restaurant_cost']} per person. \"\n",
    "    description += f\"Nearby attractions include {row['attraction_name']} with an entry fee of ${row['attraction_cost']}. \"\n",
    "    description += f\"Transportation costs approximately ${row['transportation_cost']} to get around. \"\n",
    "    \n",
    "    # Mention facilities\n",
    "    facilities = []\n",
    "    if row['Pool']:\n",
    "        facilities.append(\"Pool\")\n",
    "    if row['WiFi']:\n",
    "        facilities.append(\"Free WiFi\")\n",
    "    if row['Gym']:\n",
    "        facilities.append(\"Gym\")\n",
    "    if row['Breakfast']:\n",
    "        facilities.append(\"Breakfast included\")\n",
    "    \n",
    "    description += \"Facilities: \" + \", \".join(facilities) + \".\"\n",
    "    \n",
    "    return description.strip()\n",
    "\n",
    "# Apply preprocessing to create text descriptions\n",
    "df['cleaned_text'] = df.apply(preprocess_data, axis=1)\n",
    "\n",
    "# Prepare labeled data for intent classification\n",
    "intents_data = [\n",
    "    (\"hello\", \"greet\"),\n",
    "    (\"hi\", \"greet\"),\n",
    "    (\"best hotel in Paris\", \"best_hotel\"),\n",
    "    (\"cheapest hotel\", \"best_priced_hotel\"),\n",
    "    (\"goodbye\", \"goodbye\"),\n",
    "    (\"thanks\", \"goodbye\"),\n",
    "    # Add more examples\n",
    "]\n",
    "\n",
    "# Create DataFrame for intents\n",
    "intents_df = pd.DataFrame(intents_data, columns=[\"user_input\", \"intent\"])\n",
    "\n",
    "# Split data into features and target\n",
    "X = intents_df['user_input']\n",
    "y = intents_df['intent']\n",
    "\n",
    "# Vectorize user inputs using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifiers\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to get the most similar entry based on the user input using BERT embeddings\n",
    "def get_most_similar_entry(user_input):\n",
    "    user_input_embedding = get_bert_embeddings(user_input).reshape(1, -1)  # Reshape to 2D\n",
    "    similarities = cosine_similarity(user_input_embedding, embedding_matrix)\n",
    "    most_similar_index = np.argmax(similarities)\n",
    "    return df.iloc[most_similar_index]\n",
    "\n",
    "# Function to classify intent using multiple models and a voting mechanism\n",
    "def classify_intent(user_input):\n",
    "    user_input_vectorized = vectorizer.transform([user_input])\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    logistic_prediction = logistic_model.predict(user_input_vectorized)[0]\n",
    "    rf_prediction = random_forest_model.predict(user_input_vectorized)[0]\n",
    "    svm_prediction = svm_model.predict(user_input_vectorized)[0]\n",
    "    \n",
    "    # Use majority voting to determine the final intent\n",
    "    predictions = [logistic_prediction, rf_prediction, svm_prediction]\n",
    "    final_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "    \n",
    "    return final_prediction\n",
    "\n",
    "# Function to generate a detailed response for hotels, restaurants, or attractions\n",
    "def generate_detailed_response(entry):\n",
    "    response = f\"**{entry['hotel_name']}** in {entry['city']} costs ${entry['hotel_cost']} per night.\\n\"\n",
    "    response += f\"It has a restaurant named **{entry['restaurant_name']}** with meals averaging ${entry['restaurant_cost']} per person.\\n\"\n",
    "    response += f\"Nearby attraction: **{entry['attraction_name']}**, entry fee: ${entry['attraction_cost']}.\\n\"\n",
    "    response += f\"Transportation costs approximately ${entry['transportation_cost']} to get around.\\n\"\n",
    "    response += f\"Facilities: {', '.join(['Pool' if entry['Pool'] else '', 'Free WiFi' if entry['WiFi'] else '', 'Gym' if entry['Gym'] else '', 'Breakfast included' if entry['Breakfast'] else '']).strip(', ')}.\\n\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Function to get the best hotel in a specific city\n",
    "def get_best_hotel_in_city(city):\n",
    "    best_hotel = df[df['city'].str.lower() == city.lower()].nlargest(1, 'hotel_cost')\n",
    "    if not best_hotel.empty:\n",
    "        return best_hotel.iloc[0]\n",
    "    return None\n",
    "\n",
    "# Function to handle user input and provide responses\n",
    "def chatbot_response(user_input):\n",
    "    intent = classify_intent(user_input)\n",
    "    \n",
    "    if intent == 'greet':\n",
    "        return \"Hello! How can I assist you today?\"\n",
    "    elif intent == 'goodbye':\n",
    "        return \"Goodbye! Have a great day!\"\n",
    "    elif intent == 'best_hotel':\n",
    "        city = re.findall(r'in (\\w+)', user_input)  # Extract city from user input\n",
    "        if city:\n",
    "            city_name = city[0]\n",
    "            best_hotel_entry = get_best_hotel_in_city(city_name)\n",
    "            if best_hotel_entry is not None:\n",
    "                return generate_detailed_response(best_hotel_entry)\n",
    "            else:\n",
    "                return f\"Sorry, I couldn't find any hotels in {city_name}.\"\n",
    "    \n",
    "    elif intent == 'best_priced_hotel':\n",
    "        return get_best_priced_hotel()\n",
    "    \n",
    "    # If intent is unknown, search for the most similar entry\n",
    "    similar_entry = get_most_similar_entry(user_input)\n",
    "    \n",
    "    return generate_detailed_response(similar_entry)\n",
    "\n",
    "# Example conversation loop\n",
    "def chat():\n",
    "    print(\"Welcome to the Hotel Information Chatbot!\")\n",
    "    print(\"You can ask about hotels, restaurants, and attractions.\")\n",
    "    print(\"Type 'exit' to end the conversation.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "        \n",
    "        response = chatbot_response(user_input)\n",
    "        print(f\"Chatbot: {response}\\n\")\n",
    "\n",
    "# Start the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d411e-cf0c-4aac-93c6-24a79da6f147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd0f89-029e-4e44-9fe4-e183f5f0ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, GPT2Tokenizer, GPT2LMHeadModel\n",
    "import nltk\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Original Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Initialize BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# Initialize GPT-2 model and tokenizer for generating responses\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "gpt2_model.eval()\n",
    "\n",
    "# Function to preprocess structured fields to align with chatbot intent recognition\n",
    "def preprocess_data(row):\n",
    "    description = f\"{row['hotel_name']} in {row['city']} costs ${row['hotel_cost']} per night. \"\n",
    "    description += f\"It has a restaurant named {row['restaurant_name']} with meals averaging ${row['restaurant_cost']} per person. \"\n",
    "    description += f\"Nearby attractions include {row['attraction_name']} with an entry fee of ${row['attraction_cost']}. \"\n",
    "    description += f\"Transportation costs approximately ${row['transportation_cost']} to get around. \"\n",
    "    \n",
    "    # Mention facilities\n",
    "    facilities = []\n",
    "    if row['Pool']:\n",
    "        facilities.append(\"Pool\")\n",
    "    if row['WiFi']:\n",
    "        facilities.append(\"Free WiFi\")\n",
    "    if row['Gym']:\n",
    "        facilities.append(\"Gym\")\n",
    "    if row['Breakfast']:\n",
    "        facilities.append(\"Breakfast included\")\n",
    "    \n",
    "    description += \"Facilities: \" + \", \".join(facilities) + \".\"\n",
    "    \n",
    "    return description.strip()\n",
    "\n",
    "# Apply preprocessing to create text descriptions\n",
    "df['cleaned_text'] = df.apply(preprocess_data, axis=1)\n",
    "\n",
    "# Prepare labeled data for intent classification\n",
    "intents_data = [\n",
    "    (\"hello\", \"greet\"),\n",
    "    (\"hi\", \"greet\"),\n",
    "    (\"best hotel in Paris\", \"best_hotel\"),\n",
    "    (\"cheapest hotel\", \"best_priced_hotel\"),\n",
    "    (\"goodbye\", \"goodbye\"),\n",
    "    (\"thanks\", \"goodbye\"),\n",
    "    # Add more examples\n",
    "]\n",
    "\n",
    "# Create DataFrame for intents\n",
    "intents_df = pd.DataFrame(intents_data, columns=[\"user_input\", \"intent\"])\n",
    "\n",
    "# Split data into features and target\n",
    "X = intents_df['user_input']\n",
    "y = intents_df['intent']\n",
    "\n",
    "# Vectorize user inputs using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifiers\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Function to classify intent using multiple models and a voting mechanism\n",
    "def classify_intent(user_input):\n",
    "    user_input_vectorized = vectorizer.transform([user_input])\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    logistic_prediction = logistic_model.predict(user_input_vectorized)[0]\n",
    "    rf_prediction = random_forest_model.predict(user_input_vectorized)[0]\n",
    "    svm_prediction = svm_model.predict(user_input_vectorized)[0]\n",
    "    \n",
    "    # Use majority voting to determine the final intent\n",
    "    predictions = [logistic_prediction, rf_prediction, svm_prediction]\n",
    "    final_prediction = Counter(predictions).most_common(1)[0][0]\n",
    "    \n",
    "    return final_prediction\n",
    "\n",
    "# Function to generate a response using the GPT-2 model\n",
    "def generate_generative_response(user_input):\n",
    "    prompt = f\"User: {user_input}\\nChatbot: \"\n",
    "    inputs = gpt2_tokenizer.encode(prompt, return_tensors='pt')\n",
    "    \n",
    "    # Generate a response from the model\n",
    "    outputs = gpt2_model.generate(inputs, max_length=150, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "    response = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Remove the user prompt from the response\n",
    "    response = response.replace(prompt, \"\").strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Function to handle user input and provide responses\n",
    "def chatbot_response(user_input):\n",
    "    intent = classify_intent(user_input)\n",
    "    \n",
    "    if intent == 'greet':\n",
    "        return \"Hello! How can I assist you today?\"\n",
    "    elif intent == 'goodbye':\n",
    "        return \"Goodbye! Have a great day!\"\n",
    "    elif intent == 'best_hotel':\n",
    "        city = re.findall(r'in (\\w+)', user_input)  # Extract city from user input\n",
    "        if city:\n",
    "            city_name = city[0]\n",
    "            best_hotel_entry = get_best_hotel_in_city(city_name)\n",
    "            if best_hotel_entry is not None:\n",
    "                return generate_detailed_response(best_hotel_entry)\n",
    "            else:\n",
    "                return f\"Sorry, I couldn't find any hotels in {city_name}.\"\n",
    "    \n",
    "    elif intent == 'best_priced_hotel':\n",
    "        return get_best_priced_hotel()\n",
    "    \n",
    "    # Generate a response using GPT-2 for unknown intents\n",
    "    return generate_generative_response(user_input)\n",
    "\n",
    "# Example conversation loop\n",
    "def chat():\n",
    "    print(\"Welcome to the Hotel Information Chatbot!\")\n",
    "    print(\"You can ask about hotels, restaurants, and attractions.\")\n",
    "    print(\"Type 'exit' to end the conversation.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "        \n",
    "        response = chatbot_response(user_input)\n",
    "        print(f\"Chatbot: {response}\\n\")\n",
    "\n",
    "# Start the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7be8ea-ad98-45c5-b8bc-f87c1cf387dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4034cb88-9757-4fbc-b866-852dc58c8297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
